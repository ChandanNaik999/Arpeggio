{
    "docs": [
        {
            "location": "/",
            "text": "Arpeggio is recursive descent parser with backtracking and memoization (a.k.a.\npacrat parser).  Arpeggio grammars are based on \nPEG\nformalism\n.\n\n\nArpeggio's main use is a foundation for a tool-chain for DSL development but it\ncan be used for all sort of general purpose parsing.\n\n\nFor more information on PEG and packrat parsers see \nthis\npage\n.\n\n\nFor a higher level library for building DSLs take a look at\n\ntextX\n. It builds on top of Arpeggio\nand makes language parser implementation a lot easier.\n\n\nSee \nGetting started\n in the \nUser Guide\n menu to get you going or read some of the\ntutorials.\n\n\nFeatures\n\n\n\n\nUsing \nParsing Expression Grammar\n\n  and packrat parsing - unambiguous grammars, unlimited lookahead, linear time.\n\n\nWorks as grammar interpreter - no code is generated.\n\n\nMultiple syntaxes for grammar definition (\nPython\n, \n  \npeg, cleanpeg\n, make your own)\n\n\nCase sensitive/insensitive\n  parsing\n\n\nWhitespace handling control\n\n\nKeyword handling\n\n\nSupport for comments\n\n\nNewline termination for\n  Repetition\n (available only in Python syntax)\n\n\nParse tree navigation\n\n\nVisitors for semantic analysis\n\n\nExtensive error reporting\n\n\nGood support for debugging and visualization\n\n\nGood test coverage\n\n\nBeautiful mkdocs documentation - you are reading it\n\n\n\n\nPython versions\n\n\nArpeggio works with Python 2.7, 3.3+. Other versions might work but are not\ntested.\n\n\nOpen-source projects using Arpeggio\n\n\n\n\ntextX\n - Meta-language for building\n  Domain-Specific Languages in Python (and all projects using textX)\n\n\nwhatami\n - Unobtrusive object\n  self-identification for Python\n  (\nparsers\n\n  module)\n\n\nithkuil\n - A Python package providing\n  tools for analysing texts in the \nIthkuil\n constructed language.\n\n\n\n\nWhy is it called arpeggio?\n\n\nIn music, arpeggio is playing the chord notes one by one in sequence. I came up\nwith the name by thinking that parsing is very similar to arpeggios in music.\nYou take tokens one by one from an input and make sense out of it \u2013 make a\nchord!\n\n\nWell, if you don't buy this maybe it is time to tell you the truth. I searched\nthe dictionary for the words that contain PEG acronym and the word arpeggio was\nat the top of the list ;)\n\n\nCiting Arpeggio\n\n\nIf you use Arpeggio please cite this paper:\n\n\nDejanovi\u0107 I., Milosavljevi\u0107 G., Vaderna R.: Arpeggio: A flexible PEG parser for\nPython, Knowledge-Based Systems, 2016, 95, 71 - 74,\n\ndoi:10.1016/j.knosys.2015.12.004",
            "title": "Home"
        },
        {
            "location": "/#features",
            "text": "Using  Parsing Expression Grammar \n  and packrat parsing - unambiguous grammars, unlimited lookahead, linear time.  Works as grammar interpreter - no code is generated.  Multiple syntaxes for grammar definition ( Python , \n   peg, cleanpeg , make your own)  Case sensitive/insensitive\n  parsing  Whitespace handling control  Keyword handling  Support for comments  Newline termination for\n  Repetition  (available only in Python syntax)  Parse tree navigation  Visitors for semantic analysis  Extensive error reporting  Good support for debugging and visualization  Good test coverage  Beautiful mkdocs documentation - you are reading it",
            "title": "Features"
        },
        {
            "location": "/#python-versions",
            "text": "Arpeggio works with Python 2.7, 3.3+. Other versions might work but are not\ntested.",
            "title": "Python versions"
        },
        {
            "location": "/#open-source-projects-using-arpeggio",
            "text": "textX  - Meta-language for building\n  Domain-Specific Languages in Python (and all projects using textX)  whatami  - Unobtrusive object\n  self-identification for Python\n  ( parsers \n  module)  ithkuil  - A Python package providing\n  tools for analysing texts in the  Ithkuil  constructed language.",
            "title": "Open-source projects using Arpeggio"
        },
        {
            "location": "/#why-is-it-called-arpeggio",
            "text": "In music, arpeggio is playing the chord notes one by one in sequence. I came up\nwith the name by thinking that parsing is very similar to arpeggios in music.\nYou take tokens one by one from an input and make sense out of it \u2013 make a\nchord!  Well, if you don't buy this maybe it is time to tell you the truth. I searched\nthe dictionary for the words that contain PEG acronym and the word arpeggio was\nat the top of the list ;)",
            "title": "Why is it called arpeggio?"
        },
        {
            "location": "/#citing-arpeggio",
            "text": "If you use Arpeggio please cite this paper:  Dejanovi\u0107 I., Milosavljevi\u0107 G., Vaderna R.: Arpeggio: A flexible PEG parser for\nPython, Knowledge-Based Systems, 2016, 95, 71 - 74, doi:10.1016/j.knosys.2015.12.004",
            "title": "Citing Arpeggio"
        },
        {
            "location": "/getting_started/",
            "text": "Getting started\n\n\nInstallation and your first steps with Arpeggio.\n\n\n\n\nInstallation\n\n\nArpeggio is written in Python programming language and distributed with\nsetuptools support. If you have \npip\n tool installed the most recent stable\nversion of Arpeggio can be installed form\n\nPyPI\n with the following command:\n\n\n    $ pip install Arpeggio\n\n\n\n\nTo verify that you have installed Arpeggio correctly run the following command:\n\n\n$ python -c 'import arpeggio'\n\n\n\n\nIf you get no error, Arpeggio is correctly installed.\n\n\nTo install Arpeggio for contribution see \nhere\n.\n\n\nInstalling from source\n\n\nIf for some weird reason you don't have or don't want to use \npip\n you can still\ninstall Arpeggio from source.\n\n\nTo download source distribution do:\n\n\n\n\n\n\ndownload\n\n\n$ wget https://github.com/igordejanovic/Arpeggio/archive/v1.1.tar.gz\n\n\n\n\n\n\n\nunpack\n\n\n$ tar xzf v1.1.tar.gz\n\n\n\n\n\n\n\ninstall\n\n\n$ cd Arpeggio-1.1\n$ python setup.py install\n\n\n\n\n\n\n\nQuick start\n\n\nBasic workflow in using Arpeggio goes like this:\n\n\nWrite \na grammar\n. There are several ways to do that:\n\n\n\n\n\n\nThe canonical grammar format\n uses\n  Python statements and expressions.  Each rule is specified as Python function\n  which should return a data structure that defines the rule. For example a\n  grammar for simple calculator can be written as:\n\n\nfrom arpeggio import Optional, ZeroOrMore, OneOrMore, EOF\nfrom arpeggio import RegExMatch as _\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF\n\n\n\nThe python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG.\nFor terminal matches use plain strings or regular expressions.\n\n\n\n\n\n\nThe same grammar could also be written using \ntraditional textual PEG\n  syntax\n like this:\n\n\nnumber <- r'\\d*\\.\\d*|\\d+';  // this is a comment\nfactor <- (\"+\" / \"-\")? (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;\n\n\n\n\n\n\n\nOr similar syntax but a little bit more readable like this:\n\n\nnumber = r'\\d*\\.\\d*|\\d+'    # this is a comment\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF\n\n\n\nThe second and third options are implemented using canonical first form.\nFeel free to implement your own grammar syntax if you don't like these\n(see modules \narpeggio.peg\n and \narpeggio.cleanpeg\n).\n\n\n\n\n\n\nInstantiate a parser\n. Parser works as a grammar interpreter. There is no\ncode generation.\n\n\nfrom arpeggio import ParserPython\nparser = ParserPython(calc)   # calc is the root rule of your grammar\n                              # Use param debug=True for verbose debugging\n                              # messages and grammar and parse tree visualization\n                              # using graphviz and dot\n\n\n\n\nParse your inputs\n\n\nparse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")\n\n\n\n\nIf parsing is successful (e.g. no syntax error if found) you get a \nparse\ntree\n.\n\n\nAnalyze parse tree\n directly or write a \nvisitor class\n to\ntransform it to a more usable form.\n\n\nFor \ntextual PEG syntaxes\n\ninstead of \nParserPyton\n instantiate \nParserPEG\n from \narpeggio.peg\n or\n\narpeggio.cleanpeg\n modules. See examples how it is done.\n\n\nTo \ndebug your grammar\n set \ndebug\n parameter to \nTrue\n. A verbose\ndebug messages will be printed and a dot files will be generated for parser\nmodel (grammar) and parse tree visualization.\n\n\nHere is an image rendered using graphviz of parser model for \ncalc\n grammar.\n\n\n\n\nAnd here is an image rendered for parse tree for the above parsed \ncalc\n expression.\n\n\n\n\nRead the tutorials\n\n\nNext, you can read some of the step-by-step tutorials (\nCSV\n, \nBibTex\n,\n\nCalc\n).\n\n\nTry the examples\n\n\nArpeggio comes with \na lot of\nexamples\n. To\ninstall and play around with the examples follow the instructions from the \nREADME\nfile\n.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#getting-started",
            "text": "Installation and your first steps with Arpeggio.",
            "title": "Getting started"
        },
        {
            "location": "/getting_started/#installation",
            "text": "Arpeggio is written in Python programming language and distributed with\nsetuptools support. If you have  pip  tool installed the most recent stable\nversion of Arpeggio can be installed form PyPI  with the following command:      $ pip install Arpeggio  To verify that you have installed Arpeggio correctly run the following command:  $ python -c 'import arpeggio'  If you get no error, Arpeggio is correctly installed.  To install Arpeggio for contribution see  here .",
            "title": "Installation"
        },
        {
            "location": "/getting_started/#installing-from-source",
            "text": "If for some weird reason you don't have or don't want to use  pip  you can still\ninstall Arpeggio from source.  To download source distribution do:    download  $ wget https://github.com/igordejanovic/Arpeggio/archive/v1.1.tar.gz    unpack  $ tar xzf v1.1.tar.gz    install  $ cd Arpeggio-1.1\n$ python setup.py install",
            "title": "Installing from source"
        },
        {
            "location": "/getting_started/#quick-start",
            "text": "Basic workflow in using Arpeggio goes like this:  Write  a grammar . There are several ways to do that:    The canonical grammar format  uses\n  Python statements and expressions.  Each rule is specified as Python function\n  which should return a data structure that defines the rule. For example a\n  grammar for simple calculator can be written as:  from arpeggio import Optional, ZeroOrMore, OneOrMore, EOF\nfrom arpeggio import RegExMatch as _\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF  The python lists in the data structure represent ordered choices while the tuples represent sequences from the PEG.\nFor terminal matches use plain strings or regular expressions.    The same grammar could also be written using  traditional textual PEG\n  syntax  like this:  number <- r'\\d*\\.\\d*|\\d+';  // this is a comment\nfactor <- (\"+\" / \"-\")? (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;    Or similar syntax but a little bit more readable like this:  number = r'\\d*\\.\\d*|\\d+'    # this is a comment\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF  The second and third options are implemented using canonical first form.\nFeel free to implement your own grammar syntax if you don't like these\n(see modules  arpeggio.peg  and  arpeggio.cleanpeg ).    Instantiate a parser . Parser works as a grammar interpreter. There is no\ncode generation.  from arpeggio import ParserPython\nparser = ParserPython(calc)   # calc is the root rule of your grammar\n                              # Use param debug=True for verbose debugging\n                              # messages and grammar and parse tree visualization\n                              # using graphviz and dot  Parse your inputs  parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")  If parsing is successful (e.g. no syntax error if found) you get a  parse\ntree .  Analyze parse tree  directly or write a  visitor class  to\ntransform it to a more usable form.  For  textual PEG syntaxes \ninstead of  ParserPyton  instantiate  ParserPEG  from  arpeggio.peg  or arpeggio.cleanpeg  modules. See examples how it is done.  To  debug your grammar  set  debug  parameter to  True . A verbose\ndebug messages will be printed and a dot files will be generated for parser\nmodel (grammar) and parse tree visualization.  Here is an image rendered using graphviz of parser model for  calc  grammar.   And here is an image rendered for parse tree for the above parsed  calc  expression.",
            "title": "Quick start"
        },
        {
            "location": "/getting_started/#read-the-tutorials",
            "text": "Next, you can read some of the step-by-step tutorials ( CSV ,  BibTex , Calc ).",
            "title": "Read the tutorials"
        },
        {
            "location": "/getting_started/#try-the-examples",
            "text": "Arpeggio comes with  a lot of\nexamples . To\ninstall and play around with the examples follow the instructions from the  README\nfile .",
            "title": "Try the examples"
        },
        {
            "location": "/grammars/",
            "text": "Grammars\n\n\nWith grammar you teach Arpeggio how to parse your inputs.\n\n\n\n\nArpeggio is based\non \nPEG grammars\n. PEG\nis a type of formal grammar that is given as a set of rules for recognizing\nstrings of the language. In a way it is similar to context-free grammars with a\nvery important distinction that PEG are always unambiguous. This is achieved by\nmaking choice operator ordered. In PEGs a first choice from left to right that\nmatches will be used.\n\n\n\n\nNote\n\n\nMore information on PEGs can be found on \nthis page\n.\n\n\n\n\nPEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and\ncan reference (call) each other.\n\n\nExample grammar in PEG notation:\n\n\nfirst = 'foo' second+ EOF\nsecond = 'bar' / 'baz'\n\n\n\nIn this example \nfirst\n is the root rule. This rule will match a literal string\n\nfoo\n followed by one or more \nsecond\n rule (this is a rule reference) followed\nby end of input (\nEOF\n). \nsecond\n rule is ordered choice and will match either\n\nbar\n or \nbaz\n in that order.\n\n\nDuring parsing each successfully matched rule will create a parse tree node. At\nthe end of parsing a complete \nparse tree\n of the input will be\nreturned. .\n\n\nIn Arpeggio each PEG rule consists of atomic parsing expression which can be:\n\n\n\n\n\n\nterminal match rules\n - create\n  a \nTerminal nodes\n:\n\n\n\n\nString match\n - a simple string that is matched literally from the\n  input string.\n\n\nRegEx match\n - regular expression match (based on python \nre\n module).\n\n\n\n\n\n\n\n\nnon-terminal match rules\n - create\n  a \nNon-terminal nodes\n:\n\n\n\n\nSequence\n - succeeds if all parsing expressions matches at current\n  location in the defined order. Matched input is consumed.\n\n\nOrdered choice\n - succeeds if any of the given expressions matches at\n  the current location. The match is tried in the order defined. Matched\n  input is consumed.\n\n\nZero or more\n - given expression is matched until match is successful.\n  Always succeeds. Matched input is consumed.\n\n\nOne or more\n - given expressions is matched until match is successful.\n  Succeeds if at least one match is done. Matched input is consumed.\n\n\nOptional\n - matches given expression but will not fail if match can't be\n  done. Matched input is consumed.\n\n\nUnordered group\n - matches given expressions in any order. Each given\n  expression must be matched exacltly once. Matched input is consumed.\n\n\nAnd predicate\n - succeeds if given expression matches at current\n  location but does not consume any input.\n\n\nNot predicate\n - succeeds if given expression \ndoes not\n matches at\n  current location but does not consume any input.\n\n\n\n\n\n\n\n\nPEG grammars in Arpeggio may be written twofold:\n\n\n\n\nUsing Python statements and expressions.\n\n\nUsing textual PEG syntax (currently there are two variants, see below).\n\n\n\n\nGrammars written in Python\n\n\nCanonical form of grammar specification uses Python statements and expressions.\n\n\nHere is an example of arpeggio grammar for simple calculator:\n\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number,\n                          (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF\n\n\n\nEach rule is given in the form of Python function. Python function returns data\nstructure that maps to PEG expressions.\n\n\n\n\nSequence\n is represented as Python tuple.\n\n\nOrdered choice\n is represented as Python list where each element is one\n  alternative.\n\n\nOne or more\n is represented as an instance of \nOneOrMore\n class.\n  The parameters are treated as a containing sequence.\n\n\nZero or more\n is represented as an instance of \nZeroOrMore\n class.\n  The parameters are treated as a containing sequence.\n\n\nOptional\n is represented as an instance of \nOptional\n class.\n\n\nUnordered group\n is represented as an instance of \nUnorderedGroup\n class.\n\n\nAnd predicate\n is represented as an instance of \nAnd\n class.\n\n\nNot predicate\n is represented as an instance of \nNot\n class.\n\n\nLiteral string match\n is represented as string or regular expression given\n  as an instance of \nRegExMatch\n class.\n\n\nEnd of string/file\n is recognized by the \nEOF\n special rule.\n\n\n\n\nFor example, the \ncalc\n language consists of one or more \nexpression\n and\nend of file.\n\n\nfactor\n rule consists of optional \n+\n or \n-\n char matched in that order\n(they are given in Python list thus ordered choice) followed by the ordered\nchoice of \nnumber\n rule and a sequence of \nexpression\n rule in brackets.\nThis rule will match an optional sign (\n+\n or \n-\n tried in that order) after\nwhich follows a \nnumber\n or an \nexpression\n in brackets (tried in that\norder).\n\n\nFrom this description Arpeggio builds \nthe parser model\n. Parser model is a\ngraph of parser expressions (see \nGrammar\nvisualization\n).  Each node of the graph is\nan instance of some of the classes described above which inherits\n\nParserExpression\n.\n\n\nParser model construction is done during parser instantiation. For example, to\ninstantiate \ncalc\n parser you do the following:\n\n\nparser = ParserPython(calc)\n\n\n\n\nWhere \ncalc\n is the function defining the root rule of your grammar. There is no\ncode generation. Parser works as an interpreter for your grammar. The grammar is\nused to configure Arpeggio parser to recognize your language (in this case the\n\ncalc\n language). In other words, Arpeggio interprets the parser model (your\ngrammar).\n\n\nAfter parser construction your can call \nparser.parse\n to parse your input text.\n\n\ninput_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\nArpeggio will start from the root node and traverse \nthe parser model graph\n\nconsuming all matched input. When all root node branches are traversed the\nparsing is done and \nthe parse tree\n is returned.\n\n\nYou can navigate and analyze parse tree or transform it using visitor pattern to\nsome more usable form (see \nSemantic analysis - Visitors\n)\n\n\nGrammars written in PEG notations\n\n\nGrammars can also be specified using PEG notation. There are actually two of\nthem at the moment and both notations are implemented using canonical Python\nbased grammars (see\nmodules\n\narpeggio.peg\n and\n\narpeggio.cleanpeg\n).\n\n\nThere are no significant differences between those two syntax. The first one use\nmore traditional approach using \n<-\n for rule assignment, \n//\n for line comments\nand \n;\n for the rule terminator. The second syntax (from \narpeggio.cleanpeg\n)\nuses \n=\n for assignment, does not use rule terminator and use \n#\n for line\ncomments. Which one you choose is totally up to you. If your don't like any of\nthese syntaxes you can make your own (look at \narpeggio.peg\n and\n\narpeggio.cleanpeg\n modules as an examples).\n\n\nAn example of the \ncalc\n grammar given in PEG syntax (\narpeggio.cleanpeg\n):\n\n\nnumber = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF\n\n\n\n\nEach grammar rule is given as an assignment where the LHS is the rule name (e.g.\n\nnumber\n) and the RHS is a PEG expression.\n\n\n\n\nLiteral string matches\n are given as strings (e.g. \n\"+\"\n).\n\n\nRegex matches\n are given as strings with prefix \nr\n (e.g.\n  \nr'\\d*\\.\\d*|\\d+'\n).\n\n\nSequence\n is a space separated list of expressions (e.g. \nexpression+\n  EOF\n is a sequence of two expressions).\n\n\nOrdered choice\n is a list of expression separated with \n/\n (e.g. \n\"+\" /\n  \"-\"\n).\n\n\nOptional\n expression is specified by \n?\noperator (e.g. \nexpression?\n) and\n  matches zero or one occurrence of \nexpression\n\n\nZero or more\n expression is specified by \n*\n operator (e.g. \n(( \"*\" /\n  \"/\" ) factor)*\n).\n\n\nOne of more\n is specified by \n+\n operator (e.g. \nexpression+\n).\n\n\nUnordered group\n is specified by \n#\n operator (e.g. \nsequence#\n). It has\n  sense only if applied to the sequence expression. Elements of the sequence are\n  matched in any order.\n\n\nAnd predicate\n is specified by \n&\n operator (e.g. \n&expression\n - not\n  used in the grammar above).\n\n\nNot predicate\n is specified by \n!\n operator (e.g. \n!expression\n - not\n  used in the grammar above).\n\n\nA special rule \nEOF\n will match end of input string.\n\n\n\n\nIn the RHS a rule reference is a name of another rule. Parser will try to match\nanother rule at that location.\n\n\nLiteral string matches and regex matches follow the same rules as Python itself\nwould use for\nsingle-quoted\n\nstring literals\n,\nregarding the escaping of embedded quotes, and the translation of escape\nsequences. Literal string matches are treated as normal (non-raw) string\nliterals, and regex matches are treated as raw string literals. Triple-quoting,\nand the 'r', 'u' and 'b' prefixes, are not supported \u2013 note than in arpeggio PEG\ngrammars, all strings are Unicode, and the 'r' prefix denotes a regular\nexpression.\n\n\nCreating a parser using PEG syntax is done by the class \nParserPEG\n from the\n\narpeggio.peg\n or \narpeggio.cleanpeg\n modules.\n\n\nfrom arpeggio.cleanpeg import ParserPEG\nparser = ParserPEG(calc_grammar, \"calc\")\n\n\n\n\nWhere \ncalc_grammar\n is a string with the grammar given above and the \n\"calc\"\n\nis the name of the root rule of the grammar.\n\n\nAfter this you get the same parser as with the \nParserPython\n. There is no\ndifference at all so you can parse the same language.\n\n\ninput_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\n\n\nNote\n\n\nJust remember that using textual PEG syntax imposes a slight overhead since\nthe grammar must be parsed and the parser for your language must be built by\nsemantic analysis of grammar parse tree.  If you plan to instantiate your\nparser once and than use it many times this shall not have that much of\nperformance hit but if your workflow introduce instantiating parser each time\nyour parse some input than consider defining your grammar using Python as it\nwill start faster.  Nevertheless, the parsing performance will be the same in\nboth approach since the same code for parsing is used.",
            "title": "Grammars"
        },
        {
            "location": "/grammars/#grammars",
            "text": "With grammar you teach Arpeggio how to parse your inputs.   Arpeggio is based\non  PEG grammars . PEG\nis a type of formal grammar that is given as a set of rules for recognizing\nstrings of the language. In a way it is similar to context-free grammars with a\nvery important distinction that PEG are always unambiguous. This is achieved by\nmaking choice operator ordered. In PEGs a first choice from left to right that\nmatches will be used.   Note  More information on PEGs can be found on  this page .   PEG grammar is a set of PEG rules. PEG rules consists of parsing expressions and\ncan reference (call) each other.  Example grammar in PEG notation:  first = 'foo' second+ EOF\nsecond = 'bar' / 'baz'  In this example  first  is the root rule. This rule will match a literal string foo  followed by one or more  second  rule (this is a rule reference) followed\nby end of input ( EOF ).  second  rule is ordered choice and will match either bar  or  baz  in that order.  During parsing each successfully matched rule will create a parse tree node. At\nthe end of parsing a complete  parse tree  of the input will be\nreturned. .  In Arpeggio each PEG rule consists of atomic parsing expression which can be:    terminal match rules  - create\n  a  Terminal nodes :   String match  - a simple string that is matched literally from the\n  input string.  RegEx match  - regular expression match (based on python  re  module).     non-terminal match rules  - create\n  a  Non-terminal nodes :   Sequence  - succeeds if all parsing expressions matches at current\n  location in the defined order. Matched input is consumed.  Ordered choice  - succeeds if any of the given expressions matches at\n  the current location. The match is tried in the order defined. Matched\n  input is consumed.  Zero or more  - given expression is matched until match is successful.\n  Always succeeds. Matched input is consumed.  One or more  - given expressions is matched until match is successful.\n  Succeeds if at least one match is done. Matched input is consumed.  Optional  - matches given expression but will not fail if match can't be\n  done. Matched input is consumed.  Unordered group  - matches given expressions in any order. Each given\n  expression must be matched exacltly once. Matched input is consumed.  And predicate  - succeeds if given expression matches at current\n  location but does not consume any input.  Not predicate  - succeeds if given expression  does not  matches at\n  current location but does not consume any input.     PEG grammars in Arpeggio may be written twofold:   Using Python statements and expressions.  Using textual PEG syntax (currently there are two variants, see below).",
            "title": "Grammars"
        },
        {
            "location": "/grammars/#grammars-written-in-python",
            "text": "Canonical form of grammar specification uses Python statements and expressions.  Here is an example of arpeggio grammar for simple calculator:  def number():     return _(r'\\d*\\.\\d*|\\d+')\ndef factor():     return Optional([\"+\",\"-\"]), [number,\n                          (\"(\", expression, \")\")]\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\ndef calc():       return OneOrMore(expression), EOF  Each rule is given in the form of Python function. Python function returns data\nstructure that maps to PEG expressions.   Sequence  is represented as Python tuple.  Ordered choice  is represented as Python list where each element is one\n  alternative.  One or more  is represented as an instance of  OneOrMore  class.\n  The parameters are treated as a containing sequence.  Zero or more  is represented as an instance of  ZeroOrMore  class.\n  The parameters are treated as a containing sequence.  Optional  is represented as an instance of  Optional  class.  Unordered group  is represented as an instance of  UnorderedGroup  class.  And predicate  is represented as an instance of  And  class.  Not predicate  is represented as an instance of  Not  class.  Literal string match  is represented as string or regular expression given\n  as an instance of  RegExMatch  class.  End of string/file  is recognized by the  EOF  special rule.   For example, the  calc  language consists of one or more  expression  and\nend of file.  factor  rule consists of optional  +  or  -  char matched in that order\n(they are given in Python list thus ordered choice) followed by the ordered\nchoice of  number  rule and a sequence of  expression  rule in brackets.\nThis rule will match an optional sign ( +  or  -  tried in that order) after\nwhich follows a  number  or an  expression  in brackets (tried in that\norder).  From this description Arpeggio builds  the parser model . Parser model is a\ngraph of parser expressions (see  Grammar\nvisualization ).  Each node of the graph is\nan instance of some of the classes described above which inherits ParserExpression .  Parser model construction is done during parser instantiation. For example, to\ninstantiate  calc  parser you do the following:  parser = ParserPython(calc)  Where  calc  is the function defining the root rule of your grammar. There is no\ncode generation. Parser works as an interpreter for your grammar. The grammar is\nused to configure Arpeggio parser to recognize your language (in this case the calc  language). In other words, Arpeggio interprets the parser model (your\ngrammar).  After parser construction your can call  parser.parse  to parse your input text.  input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)  Arpeggio will start from the root node and traverse  the parser model graph \nconsuming all matched input. When all root node branches are traversed the\nparsing is done and  the parse tree  is returned.  You can navigate and analyze parse tree or transform it using visitor pattern to\nsome more usable form (see  Semantic analysis - Visitors )",
            "title": "Grammars written in Python"
        },
        {
            "location": "/grammars/#grammars-written-in-peg-notations",
            "text": "Grammars can also be specified using PEG notation. There are actually two of\nthem at the moment and both notations are implemented using canonical Python\nbased grammars (see\nmodules arpeggio.peg  and arpeggio.cleanpeg ).  There are no significant differences between those two syntax. The first one use\nmore traditional approach using  <-  for rule assignment,  //  for line comments\nand  ;  for the rule terminator. The second syntax (from  arpeggio.cleanpeg )\nuses  =  for assignment, does not use rule terminator and use  #  for line\ncomments. Which one you choose is totally up to you. If your don't like any of\nthese syntaxes you can make your own (look at  arpeggio.peg  and arpeggio.cleanpeg  modules as an examples).  An example of the  calc  grammar given in PEG syntax ( arpeggio.cleanpeg ):  number = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")? (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF  Each grammar rule is given as an assignment where the LHS is the rule name (e.g. number ) and the RHS is a PEG expression.   Literal string matches  are given as strings (e.g.  \"+\" ).  Regex matches  are given as strings with prefix  r  (e.g.\n   r'\\d*\\.\\d*|\\d+' ).  Sequence  is a space separated list of expressions (e.g.  expression+\n  EOF  is a sequence of two expressions).  Ordered choice  is a list of expression separated with  /  (e.g.  \"+\" /\n  \"-\" ).  Optional  expression is specified by  ? operator (e.g.  expression? ) and\n  matches zero or one occurrence of  expression  Zero or more  expression is specified by  *  operator (e.g.  (( \"*\" /\n  \"/\" ) factor)* ).  One of more  is specified by  +  operator (e.g.  expression+ ).  Unordered group  is specified by  #  operator (e.g.  sequence# ). It has\n  sense only if applied to the sequence expression. Elements of the sequence are\n  matched in any order.  And predicate  is specified by  &  operator (e.g.  &expression  - not\n  used in the grammar above).  Not predicate  is specified by  !  operator (e.g.  !expression  - not\n  used in the grammar above).  A special rule  EOF  will match end of input string.   In the RHS a rule reference is a name of another rule. Parser will try to match\nanother rule at that location.  Literal string matches and regex matches follow the same rules as Python itself\nwould use for\nsingle-quoted string literals ,\nregarding the escaping of embedded quotes, and the translation of escape\nsequences. Literal string matches are treated as normal (non-raw) string\nliterals, and regex matches are treated as raw string literals. Triple-quoting,\nand the 'r', 'u' and 'b' prefixes, are not supported \u2013 note than in arpeggio PEG\ngrammars, all strings are Unicode, and the 'r' prefix denotes a regular\nexpression.  Creating a parser using PEG syntax is done by the class  ParserPEG  from the arpeggio.peg  or  arpeggio.cleanpeg  modules.  from arpeggio.cleanpeg import ParserPEG\nparser = ParserPEG(calc_grammar, \"calc\")  Where  calc_grammar  is a string with the grammar given above and the  \"calc\" \nis the name of the root rule of the grammar.  After this you get the same parser as with the  ParserPython . There is no\ndifference at all so you can parse the same language.  input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)   Note  Just remember that using textual PEG syntax imposes a slight overhead since\nthe grammar must be parsed and the parser for your language must be built by\nsemantic analysis of grammar parse tree.  If you plan to instantiate your\nparser once and than use it many times this shall not have that much of\nperformance hit but if your workflow introduce instantiating parser each time\nyour parse some input than consider defining your grammar using Python as it\nwill start faster.  Nevertheless, the parsing performance will be the same in\nboth approach since the same code for parsing is used.",
            "title": "Grammars written in PEG notations"
        },
        {
            "location": "/parse_trees/",
            "text": "Parse trees\n\n\nParse tree is a first structure you get from a successful parse.\n\n\n\n\nParse tree or concrete syntax tree is a tree structure built from the input\nstring during parsing.  It represent the structure of the input string. Each\nnode in the parse tree is either a \nterminal\n or\n\nnon-terminal\n. Terminals are the leafs of the tree while\nthe inner nodes are non-terminals.\n\n\nHere is an example parse tree for the \ncalc\n grammar and the expression\n\n-(4-1)*5+(2+4.67)+5.89/(.2+7)\n:\n\n\n\n\nEach non-leaf node is non-terminal. The name in this nodes are the names of the\ngrammar PEG rules that created them.\n\n\nThe leaf nodes are terminals and they are matched by the \nstring match\n or \nregex\nmatch\n rules.\n\n\nIn the square brackets is the location in the input stream where the\nterminal/non-terminal is recognized.\n\n\nEach parse tree node has the following attributes:\n\n\n\n\nrule\n - the parsing expression that created this node.\n\n\nrule_name\n - the name of the rule if it was the root rule or empty string\n  otherwise.\n\n\nposition\n - the position in the input stream where this node was\n  recognized.\n\n\nposition_end\n - the end of the node in the input stream. This index is one\n  char behind the last char that belongs to this node. Thus, \nposition_end -\n  position == length of the node\n.\n\n\n\n\nIf you want to get line and column from position you can use \npos_to_linecol\n\nparser method.\n\n\n  line, col = parser.pos_to_linecol(node.position)\n\n\n\n\nTerminal nodes\n\n\nTerminals in Arpeggio are created by the specializations of the parsing\nexpression \nMatch\n class.  There are two specialization of \nMatch\n class:\n\n\n\n\nStrMatch\n if the literal string is matched from the input or\n\n\nRegExMatch\n if a regular expression is used to match input.\n\n\n\n\nTo get the matched string from the terminal object just convert it to string\n(e.g. \nstr(t)\n where \nt\n is of \nTerminal\n type).\n\n\nNon-terminal nodes\n\n\nNon-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG\ngrammar rules.  Children of non-terminals can be other non-terminals or\nterminals.\n\n\nFor example, nodes with the labels \nexpression\n, \nfactor\n and \nterm\n from\nthe above parse tree are non-terminal nodes created by the rules with the same\nnames.\n\n\nNonTerminal\n inherits from \nlist\n. The elements of \nNonTerminal\n are its\nchildren nodes.  So, you can use index access:\n\n\nchild = pt_node[2]\n\n\n\n\nOr iteration:\n\n\nfor child in pt_node:\n  ...\n\n\n\n\nAdditionally, you can access children by the child rule name:\n\n\nFor example:\n\n\n# Grammar\ndef foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar)\ndef bar(): return \"bar\"\ndef baz(): return \"baz\"\n\n# Parsing\nparser = ParserPython(foo)\nresult = parser.parse(\"a bar b baz c bar bar bar\")\n\n# Accessing parse tree nodes. All asserts will pass.\n# Index access\nassert result[1].rule_name  == 'bar'\n# Access by rule name\nassert result.bar.rule_name == 'bar'\n\n# There are 8 children nodes of the root 'result' node.\n# Each child is a terminal in this case.\nassert len(result) == 8\n\n# There is 4 bar matched from result (at the beginning and from ZeroOrMore)\n# Dot access collect all NTs from the given path\nassert len(result.bar) == 4\n# You could call dot access recursively, e.g. result.bar.baz if the\n# rule bar called baz. In that case all bars would be collected from\n# the root and for each bar all baz will be collected.\n\n# Verify position\n# First 'bar' is at position 2 and second is at position 14\nassert result.bar[0].position == 2\nassert result.bar[1].position == 14\n\n\n\n\n\nParse tree reduction\n\n\nParser can be configured to create a reduced parse tree. More information can be\nfound \nhere\n.",
            "title": "Parse tree"
        },
        {
            "location": "/parse_trees/#parse-trees",
            "text": "Parse tree is a first structure you get from a successful parse.   Parse tree or concrete syntax tree is a tree structure built from the input\nstring during parsing.  It represent the structure of the input string. Each\nnode in the parse tree is either a  terminal  or non-terminal . Terminals are the leafs of the tree while\nthe inner nodes are non-terminals.  Here is an example parse tree for the  calc  grammar and the expression -(4-1)*5+(2+4.67)+5.89/(.2+7) :   Each non-leaf node is non-terminal. The name in this nodes are the names of the\ngrammar PEG rules that created them.  The leaf nodes are terminals and they are matched by the  string match  or  regex\nmatch  rules.  In the square brackets is the location in the input stream where the\nterminal/non-terminal is recognized.  Each parse tree node has the following attributes:   rule  - the parsing expression that created this node.  rule_name  - the name of the rule if it was the root rule or empty string\n  otherwise.  position  - the position in the input stream where this node was\n  recognized.  position_end  - the end of the node in the input stream. This index is one\n  char behind the last char that belongs to this node. Thus,  position_end -\n  position == length of the node .   If you want to get line and column from position you can use  pos_to_linecol \nparser method.    line, col = parser.pos_to_linecol(node.position)",
            "title": "Parse trees"
        },
        {
            "location": "/parse_trees/#terminal-nodes",
            "text": "Terminals in Arpeggio are created by the specializations of the parsing\nexpression  Match  class.  There are two specialization of  Match  class:   StrMatch  if the literal string is matched from the input or  RegExMatch  if a regular expression is used to match input.   To get the matched string from the terminal object just convert it to string\n(e.g.  str(t)  where  t  is of  Terminal  type).",
            "title": "Terminal nodes"
        },
        {
            "location": "/parse_trees/#non-terminal-nodes",
            "text": "Non-terminal nodes are non-leaf nodes of the parse tree. They are created by PEG\ngrammar rules.  Children of non-terminals can be other non-terminals or\nterminals.  For example, nodes with the labels  expression ,  factor  and  term  from\nthe above parse tree are non-terminal nodes created by the rules with the same\nnames.  NonTerminal  inherits from  list . The elements of  NonTerminal  are its\nchildren nodes.  So, you can use index access:  child = pt_node[2]  Or iteration:  for child in pt_node:\n  ...  Additionally, you can access children by the child rule name:  For example:  # Grammar\ndef foo(): return \"a\", bar, \"b\", baz, \"c\", ZeroOrMore(bar)\ndef bar(): return \"bar\"\ndef baz(): return \"baz\"\n\n# Parsing\nparser = ParserPython(foo)\nresult = parser.parse(\"a bar b baz c bar bar bar\")\n\n# Accessing parse tree nodes. All asserts will pass.\n# Index access\nassert result[1].rule_name  == 'bar'\n# Access by rule name\nassert result.bar.rule_name == 'bar'\n\n# There are 8 children nodes of the root 'result' node.\n# Each child is a terminal in this case.\nassert len(result) == 8\n\n# There is 4 bar matched from result (at the beginning and from ZeroOrMore)\n# Dot access collect all NTs from the given path\nassert len(result.bar) == 4\n# You could call dot access recursively, e.g. result.bar.baz if the\n# rule bar called baz. In that case all bars would be collected from\n# the root and for each bar all baz will be collected.\n\n# Verify position\n# First 'bar' is at position 2 and second is at position 14\nassert result.bar[0].position == 2\nassert result.bar[1].position == 14",
            "title": "Non-terminal nodes"
        },
        {
            "location": "/parse_trees/#parse-tree-reduction",
            "text": "Parser can be configured to create a reduced parse tree. More information can be\nfound  here .",
            "title": "Parse tree reduction"
        },
        {
            "location": "/handling_errors/",
            "text": "Handling syntax errors in the input\n\n\nThis section explains how to handle parsing errors.\n\n\n\n\nIf your grammar is correct but you get input string with syntax error parser\nwill raise \nNoMatch\n exception with the information where in the input stream\nerror has occurred and what the parser expect to see at that location.\n\n\nBy default, if \nNoMatch\n is not caught you will get detailed explanation of\nthe error at the console.  The exact location will be reported, the context\n(part of the input where the error occurred) and all the rules that were tried\nat that location.\n\n\nExample:\n\n\nparser = ParserPython(calc)\n# 'r' in the following expression can't be recognized by\n# calc grammar\ninput_expr = \"23+4/r-89\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\nAs there is an error in the \ninput_expr\n string (\nr\n is not expected) the \nfollowing traceback will be printed:\n\n\nTraceback (most recent call last):\n  ...\narpeggio.NoMatch: Expected '+' or '-' or 'number' or \n  '(' at position (1, 6) => '23+4/*r-89'.\n\n\n\nThe place in the input stream is marked by \n*\n and the position in (line,\ncolumn) is given (\n(1, 6)\n).\n\n\nIf you wish to handle syntax errors gracefully you can catch \nNoMatch\n in your\ncode and inspect its attributes.\n\n\ntry:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  # Do something with e\n\n\n\n\nNoMatch\n class has the following attributes:\n\n\n\n\nrules\n - A list of \nParsingExpression\n rules that are the sources of the\n  exception.\n\n\nposition\n - A position in the input stream where exception occurred.\n\n\nline\n, \ncol\n - A line and column in the input stream where exception\n  occurred.\n\n\nparser\n - A \nParser\n instance used for parsing.\n\n\n\n\nArpeggio is a backtracking parser, which means that it will go back and try\nanother alternatives when the match does not succeeds. Nevertheless, it will \nreport the furthest place in the input where it failed. Arpeggio will\nreport all \nMatch\n rules that failed at that position.",
            "title": "Handling errors"
        },
        {
            "location": "/handling_errors/#handling-syntax-errors-in-the-input",
            "text": "This section explains how to handle parsing errors.   If your grammar is correct but you get input string with syntax error parser\nwill raise  NoMatch  exception with the information where in the input stream\nerror has occurred and what the parser expect to see at that location.  By default, if  NoMatch  is not caught you will get detailed explanation of\nthe error at the console.  The exact location will be reported, the context\n(part of the input where the error occurred) and all the rules that were tried\nat that location.  Example:  parser = ParserPython(calc)\n# 'r' in the following expression can't be recognized by\n# calc grammar\ninput_expr = \"23+4/r-89\"\nparse_tree = parser.parse(input_expr)  As there is an error in the  input_expr  string ( r  is not expected) the \nfollowing traceback will be printed:  Traceback (most recent call last):\n  ...\narpeggio.NoMatch: Expected '+' or '-' or 'number' or \n  '(' at position (1, 6) => '23+4/*r-89'.  The place in the input stream is marked by  *  and the position in (line,\ncolumn) is given ( (1, 6) ).  If you wish to handle syntax errors gracefully you can catch  NoMatch  in your\ncode and inspect its attributes.  try:\n  parser = ParserPython(calc)\n  input_expr = \"23+4/r-89\"\n  parse_tree = parser.parse(input_expr)\nexcept NoMatch as e:\n  # Do something with e  NoMatch  class has the following attributes:   rules  - A list of  ParsingExpression  rules that are the sources of the\n  exception.  position  - A position in the input stream where exception occurred.  line ,  col  - A line and column in the input stream where exception\n  occurred.  parser  - A  Parser  instance used for parsing.   Arpeggio is a backtracking parser, which means that it will go back and try\nanother alternatives when the match does not succeeds. Nevertheless, it will \nreport the furthest place in the input where it failed. Arpeggio will\nreport all  Match  rules that failed at that position.",
            "title": "Handling syntax errors in the input"
        },
        {
            "location": "/debugging/",
            "text": "Debugging\n\n\nWhen the stuff goes wrong you will want to debug your parser.\n\n\n\n\nParser debug mode\n\n\nDuring grammar design you can make syntax and semantic errors. Arpeggio will\nreport any syntax error with all the necessary information whether you are\nbuilding parser from python expressions or from a textual PEG notation.\n\n\nFor semantic error you have a debugging mode of operation which is entered by\nsetting \ndebug\n parameter to \nTrue\n in the parser construction call. \n\n\nparser = ParserPython(calc, debug=True)\n\n\n\n\nWhen Arpeggio runs in debug mode it will print a detailed information of what it\nis doing.\n\n\n>> Entering rule calc=Sequence at position 0 => *-(4-1)*5+(\n  >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+(\n      >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+(\n        >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+(\n            >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+(\n              >> Entering rule Optional in factor at position 0 => *-(4-1)*5+(\n                  >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+(\n                    >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+(\n                        -- No match '+' at 0 => '*-*(4-1)*5+('\n                    >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+(\n                        ++ Match '-' at 0 => '*-*(4-1)*5+('\n                  << Leaving rule OrderedChoice\n              << Leaving rule Optional\n              >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2\n\n\n\nVisualization\n\n\nFurthermore, while running in debug mode, a \ndot\n file (a graph description file\nformat from \nGraphViz software\npackage\n) representing \nthe parser\nmodel\n ill be created if the parser model is constructed without errors. \n\n\nThis \ndot\n file can be rendered as image using one of available dot viewer\nsoftware or transformed to an image using \ndot\n tool\n\nGraphViz\n software.\n\n\n$ dot -Tpng -O calc_parser_model.dot\n\n\n\n\nAfter this command you will get \ncalc_parser_model.dot.png\n file which can be\nopened in any \npng\n image viewer. This is how it looks like:\n\n\n\n\nEach node in this graph is a parsing expression.  Nodes are labeled by the type\nname of the parsing expression.  If node represents the rule from the grammar\nthe label is of the form \n<rule_name>=<PEG type>\n where \nrule_name\n it the\nname of the grammar rule.  The edges connect children expressions. The labels on\nthe edges represent the order in which the graph will be traversed during\nparsing.\n\n\nFurthermore, if you parse some input while the parser is in debug mode, the\nparse tree \ndot\n file will be generated also.\n\n\nparse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")\n\n\n\n\nThis \ndot\n file can also be converted to \npng\n with the command:\n\n\n$ dot -Tpng -O calc_parse_tree.dot\n\n\n\n\nWhich produces \npng\n image given bellow.\n\n\n\n\nYou can also explicitly render your parser model or parse tree to \ndot\n file\neven if the parser is not in the debug mode.\n\n\nFor parser model this is achieved with the following Python code:\n\n\nfrom arpeggio.export import PMDOTExporter\nPMDOTExporter().exportFile(parser.parser_model,\n                            \"my_parser_model.dot\")\n\n\n\n\nFor parse tree it is achieved with:\n\n\nfrom arpeggio.export import PTDOTExporter\nPTDOTExporter().exportFile(parse_tree,\n                           \"my_parse_tree.dot\")\n\n\n\n\nTo get e.g. \npng\n images from \ndot\n files do as usuall:\n\n\n$ dot -Tpng -O *dot\n\n\n\n\n\n\n\nNote\n\n\nAll tree images in this docs are rendered using Arpeggio's visualization and\n\ndot\n tool from the \nGraphViz\n software.",
            "title": "Debugging"
        },
        {
            "location": "/debugging/#debugging",
            "text": "When the stuff goes wrong you will want to debug your parser.",
            "title": "Debugging"
        },
        {
            "location": "/debugging/#parser-debug-mode",
            "text": "During grammar design you can make syntax and semantic errors. Arpeggio will\nreport any syntax error with all the necessary information whether you are\nbuilding parser from python expressions or from a textual PEG notation.  For semantic error you have a debugging mode of operation which is entered by\nsetting  debug  parameter to  True  in the parser construction call.   parser = ParserPython(calc, debug=True)  When Arpeggio runs in debug mode it will print a detailed information of what it\nis doing.  >> Entering rule calc=Sequence at position 0 => *-(4-1)*5+(\n  >> Entering rule OneOrMore in calc at position 0 => *-(4-1)*5+(\n      >> Entering rule expression=Sequence in calc at position 0 => *-(4-1)*5+(\n        >> Entering rule term=Sequence in expression at position 0 => *-(4-1)*5+(\n            >> Entering rule factor=Sequence in term at position 0 => *-(4-1)*5+(\n              >> Entering rule Optional in factor at position 0 => *-(4-1)*5+(\n                  >> Entering rule OrderedChoice in factor at position 0 => *-(4-1)*5+(\n                    >> Match rule StrMatch(+) in factor at position 0 => *-(4-1)*5+(\n                        -- No match '+' at 0 => '*-*(4-1)*5+('\n                    >> Match rule StrMatch(-) in factor at position 0 => *-(4-1)*5+(\n                        ++ Match '-' at 0 => '*-*(4-1)*5+('\n                  << Leaving rule OrderedChoice\n              << Leaving rule Optional\n              >> Entering rule OrderedChoice in factor at position 1 => -*(4-1)*5+(2",
            "title": "Parser debug mode"
        },
        {
            "location": "/debugging/#visualization",
            "text": "Furthermore, while running in debug mode, a  dot  file (a graph description file\nformat from  GraphViz software\npackage ) representing  the parser\nmodel  ill be created if the parser model is constructed without errors.   This  dot  file can be rendered as image using one of available dot viewer\nsoftware or transformed to an image using  dot  tool GraphViz  software.  $ dot -Tpng -O calc_parser_model.dot  After this command you will get  calc_parser_model.dot.png  file which can be\nopened in any  png  image viewer. This is how it looks like:   Each node in this graph is a parsing expression.  Nodes are labeled by the type\nname of the parsing expression.  If node represents the rule from the grammar\nthe label is of the form  <rule_name>=<PEG type>  where  rule_name  it the\nname of the grammar rule.  The edges connect children expressions. The labels on\nthe edges represent the order in which the graph will be traversed during\nparsing.  Furthermore, if you parse some input while the parser is in debug mode, the\nparse tree  dot  file will be generated also.  parse_tree = parser.parse(\"-(4-1)*5+(2+4.67)+5.89/(.2+7)\")  This  dot  file can also be converted to  png  with the command:  $ dot -Tpng -O calc_parse_tree.dot  Which produces  png  image given bellow.   You can also explicitly render your parser model or parse tree to  dot  file\neven if the parser is not in the debug mode.  For parser model this is achieved with the following Python code:  from arpeggio.export import PMDOTExporter\nPMDOTExporter().exportFile(parser.parser_model,\n                            \"my_parser_model.dot\")  For parse tree it is achieved with:  from arpeggio.export import PTDOTExporter\nPTDOTExporter().exportFile(parse_tree,\n                           \"my_parse_tree.dot\")  To get e.g.  png  images from  dot  files do as usuall:  $ dot -Tpng -O *dot   Note  All tree images in this docs are rendered using Arpeggio's visualization and dot  tool from the  GraphViz  software.",
            "title": "Visualization"
        },
        {
            "location": "/configuration/",
            "text": "Parser configuration\n\n\nThis section describes how to alter parser default behaviour.\n\n\n\n\nThere are some aspect of parsing that can be configured using parser and/or\n\nParsingExpression\n parameters.  Arpeggio has some sane default behaviour but\ngives the user possibility to alter it.\n\n\nThis section describes various parser parameters.\n\n\nCase insensitive parsing\n\n\nBy default Arpeggio is case sensitive. If you wish to do case insensitive\nparsing set parser parameter \nignore_case\n to \nTrue\n.\n\n\nparser = ParserPython(calc, ignore_case=True)\n\n\n\n\nWhite-space handling\n\n\nArpeggio by default skips white-spaces. You can change this behaviour with the\nparameter \nskipws\n given to parser constructor.\n\n\nparser = ParserPython(calc, skipws=False)\n\n\n\n\nYou can also change what is considered a whitespace by Arpeggio using the \nws\n\nparameter. It is a plain string that consists of white-space characters. By\ndefault it is set to \n\"\\t\\n\\r \"\n.\n\n\nFor example, to prevent a newline to be treated as whitespace you could write:\n\n\nparser = ParserPython(calc, ws='\\t\\r ')\n\n\n\n\n\n\nNote\n\n\nThese parameters can be used on the \nSequence\n level so one could write\ngrammar like this:\n\n\ndef grammar():     return Sequence(\"one\", \"two\", \"three\", skipws=False),\n                                   \"four\"\nparser = ParserPython(grammar)\npt = parser.parse(\"onetwothree four\")\n\n\n\n\n\nKeyword handling\n\n\nBy setting a \nautokwd\n parameter to \nTrue\n a word boundary match for\nkeyword-like matches will be performed.\n\n\nThis parameter is disabled by default.\n\n\n  def grammar():     return \"one\", \"two\", \"three\"\n\n  parser = ParserPython(grammar, autokwd=True)\n\n  # If autokwd is enabled this should parse without error.\n  parser.parse(\"one two three\")\n\n  # But this will not parse as the match is done using word boundaries\n  # so this is considered a one word.\n  parser.parse(\"onetwothree\")\n\n\n\nComment handling\n\n\nSupport for comments in your language can be specified as another set of\ngrammar rules.  See \nsimple.py\nexample\n.\n\n\nParser is constructed using two parameters.\n\n\nparser = ParserPython(simpleLanguage, comment)\n\n\n\n\nFirst parameter is the root rule of main parse model while the second is a rule\nfor comments.\n\n\nDuring parsing comment parse trees are kept in the separate list thus comments\nwill not show in the main parse tree.\n\n\nParse tree reduction\n\n\nNon-terminals are by default created for each rule. Sometimes it can result in\ntrees of great depth.  You can alter this behaviour setting \nreduce_tree\n\nparameter to \nTrue\n.\n\n\nparser = ParserPython(calc, reduce_tree=True)\n\n\n\n\nIn this configuration non-terminals with single child will be removed from the\nparse tree.\n\n\nFor example, \ncalc\n parse tree above will look like this:\n\n\n\n\nNotice the removal of each non-terminal with single child.\n\n\n\n\nWarning\n\n\nBe aware that \nsemantic analysis\n operates on nodes of\nfinished parse tree. Therefore, it you use \ntree\nreduction\n visitor methods will not\nget called for the removed nodes.\n\n\n\n\nNewline termination for Repetitions\n\n\nBy default \nRepetition\n parsing expressions (i.e. \nZeroOrMore\n and\n\nOneOrMore\n) will obey \nskipws\n and \nws\n settings but there are situations\nwhere repetitions should not pass the end of the current line. For this feature\n\neolterm\n parameter is introduced which can be set on a repetition and will\nensure that it terminates before entering a new line.\n\n\ndef grammar():      return first, second\ndef first():        return ZeroOrMore([\"a\", \"b\"], eolterm=True)\ndef second():       return \"a\"\n\n# first rule should match only first line\n# so that second rule will match \"a\" on the new line\ninput = \"\"\"a a b a b b\na\"\"\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)\n\n\n\nSeparator for Repetitions\n\n\nIt is possible to specify parsing expression that will be used in between each\ntwo matches in repetitions.\n\n\nFor example:\n\n\ndef grammar():        return ZeroOrMore([\"a\", \"b\"], sep=\",\")\n\n# so that second rule will match \"a\" on the new line\ninput = \"a , b, b, a\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)\n\n\n\nsep\n can be any valid parsing expression.\n\n\nMemoization (a.k.a. packrat parsing)\n\n\nThis technique is based on memoizing result on each parsing expression rule.\nFor some grammars with a lot of backtracking this can yield a significant\nspeed increase at the expense of some memory used for the memoization cache.\n\n\nStarting with Arpeggio 1.5 this feature is disabled by default.  If you think\nthat parsing is slow, try to enable memoization by setting \nmemoization\n\nparameter to \nTrue\n during parser instantiation.\n\n\nparser = ParserPython(grammar, memoization=True)",
            "title": "Parser configuration"
        },
        {
            "location": "/configuration/#parser-configuration",
            "text": "This section describes how to alter parser default behaviour.   There are some aspect of parsing that can be configured using parser and/or ParsingExpression  parameters.  Arpeggio has some sane default behaviour but\ngives the user possibility to alter it.  This section describes various parser parameters.",
            "title": "Parser configuration"
        },
        {
            "location": "/configuration/#case-insensitive-parsing",
            "text": "By default Arpeggio is case sensitive. If you wish to do case insensitive\nparsing set parser parameter  ignore_case  to  True .  parser = ParserPython(calc, ignore_case=True)",
            "title": "Case insensitive parsing"
        },
        {
            "location": "/configuration/#white-space-handling",
            "text": "Arpeggio by default skips white-spaces. You can change this behaviour with the\nparameter  skipws  given to parser constructor.  parser = ParserPython(calc, skipws=False)  You can also change what is considered a whitespace by Arpeggio using the  ws \nparameter. It is a plain string that consists of white-space characters. By\ndefault it is set to  \"\\t\\n\\r \" .  For example, to prevent a newline to be treated as whitespace you could write:  parser = ParserPython(calc, ws='\\t\\r ')   Note  These parameters can be used on the  Sequence  level so one could write\ngrammar like this:  def grammar():     return Sequence(\"one\", \"two\", \"three\", skipws=False),\n                                   \"four\"\nparser = ParserPython(grammar)\npt = parser.parse(\"onetwothree four\")",
            "title": "White-space handling"
        },
        {
            "location": "/configuration/#keyword-handling",
            "text": "By setting a  autokwd  parameter to  True  a word boundary match for\nkeyword-like matches will be performed.  This parameter is disabled by default.    def grammar():     return \"one\", \"two\", \"three\"\n\n  parser = ParserPython(grammar, autokwd=True)\n\n  # If autokwd is enabled this should parse without error.\n  parser.parse(\"one two three\")\n\n  # But this will not parse as the match is done using word boundaries\n  # so this is considered a one word.\n  parser.parse(\"onetwothree\")",
            "title": "Keyword handling"
        },
        {
            "location": "/configuration/#comment-handling",
            "text": "Support for comments in your language can be specified as another set of\ngrammar rules.  See  simple.py\nexample .  Parser is constructed using two parameters.  parser = ParserPython(simpleLanguage, comment)  First parameter is the root rule of main parse model while the second is a rule\nfor comments.  During parsing comment parse trees are kept in the separate list thus comments\nwill not show in the main parse tree.",
            "title": "Comment handling"
        },
        {
            "location": "/configuration/#parse-tree-reduction",
            "text": "Non-terminals are by default created for each rule. Sometimes it can result in\ntrees of great depth.  You can alter this behaviour setting  reduce_tree \nparameter to  True .  parser = ParserPython(calc, reduce_tree=True)  In this configuration non-terminals with single child will be removed from the\nparse tree.  For example,  calc  parse tree above will look like this:   Notice the removal of each non-terminal with single child.   Warning  Be aware that  semantic analysis  operates on nodes of\nfinished parse tree. Therefore, it you use  tree\nreduction  visitor methods will not\nget called for the removed nodes.",
            "title": "Parse tree reduction"
        },
        {
            "location": "/configuration/#newline-termination-for-repetitions",
            "text": "By default  Repetition  parsing expressions (i.e.  ZeroOrMore  and OneOrMore ) will obey  skipws  and  ws  settings but there are situations\nwhere repetitions should not pass the end of the current line. For this feature eolterm  parameter is introduced which can be set on a repetition and will\nensure that it terminates before entering a new line.  def grammar():      return first, second\ndef first():        return ZeroOrMore([\"a\", \"b\"], eolterm=True)\ndef second():       return \"a\"\n\n# first rule should match only first line\n# so that second rule will match \"a\" on the new line\ninput = \"\"\"a a b a b b\na\"\"\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)",
            "title": "Newline termination for Repetitions"
        },
        {
            "location": "/configuration/#separator-for-repetitions",
            "text": "It is possible to specify parsing expression that will be used in between each\ntwo matches in repetitions.  For example:  def grammar():        return ZeroOrMore([\"a\", \"b\"], sep=\",\")\n\n# so that second rule will match \"a\" on the new line\ninput = \"a , b, b, a\"\n\nparser = ParserPython(grammar)\nresult = parser.parse(input)  sep  can be any valid parsing expression.",
            "title": "Separator for Repetitions"
        },
        {
            "location": "/configuration/#memoization-aka-packrat-parsing",
            "text": "This technique is based on memoizing result on each parsing expression rule.\nFor some grammars with a lot of backtracking this can yield a significant\nspeed increase at the expense of some memory used for the memoization cache.  Starting with Arpeggio 1.5 this feature is disabled by default.  If you think\nthat parsing is slow, try to enable memoization by setting  memoization \nparameter to  True  during parser instantiation.  parser = ParserPython(grammar, memoization=True)",
            "title": "Memoization (a.k.a. packrat parsing)"
        },
        {
            "location": "/semantics/",
            "text": "Semantic analysis - Visitors\n\n\nThis section explains how to transform parse tree to a more usable structure.\n\n\n\n\nYou will surely always want to extract some information from the parse tree or\nto transform it in some more usable form.  The process of parse tree\ntransformation to other forms is referred to as \nsemantic analysis\n.  You could\ndo that using parse tree navigation etc. but it is better to use some standard\nmechanism.\n\n\nIn Arpeggio a visitor pattern is used for semantic analysis. You write a python\nclass that inherits \nPTNodeVisitor\n and has a methods of the form\n\nvisit_<rule name>(self, node, children)\n where rule name is a rule name from\nthe grammar.\n\n\nclass CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        return float(node.value)\n\n    def visit_factor(self, node, children):\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]\n\n    ...\n\n\n\nDuring a semantic analysis a parse tree is walked in the depth-first manner and\nfor each node a proper visitor method is called to transform it to some other\nform. The results are than fed to the parent node visitor method.  This is\nrepeated until the final, top level parse tree node is processed (its visitor is\ncalled). The result of the top level node is the final output of the semantic\nanalysis.\n\n\nTo run semantic analysis apply your visitor class to the parse tree using\n\nvisit_parse_tree\n function.\n\n\nresult = visit_parse_tree(parse_tree, CalcVisitor(debug=True))\n\n\n\n\nThe first parameter is a parse tree you get from the \nparser.parse\n call while\nthe second parameter is an instance of your visitor class. Semantic analysis can\nbe run in debug mode if you set \ndebug\n parameter to \nTrue\n during visitor\nconstruction. You can use this flag to print your own debug information from\nvisitor methods.\n\n\nclass MyLanguageVisitor(PTNodeVisitor):\n\n  def visit_somerule(self, node, children):\n    if self.debug:\n      print(\"Visiting some rule!\")\n\n\n\nDuring semantic analysis, each \nvisitor_xxx\n method gets current parse tree node\nas the \nnode\n parameter and the evaluated children nodes as the \nchildren\n\nparameter.\n\n\nFor example, if you have \nexpression\n rule in your grammar than the\ntransformation of the non-terminal matched by this rule can be done as:\n\n\ndef visitor_expression(self, node, children):\n  ... # transform node using 'node' and 'children' parameter\n  return transformed_node\n\n\n\nnode\n is the current \nNonTerminal\n or \nTerminal\n from the parse tree while the\n\nchildren\n is an instance of \nSemanticActionResults\n class. This class is a\nlist-like structure that holds the results of semantic evaluation from the\nchildren parse tree nodes (analysis is done bottom-up).\n\n\nTo suppress node completely return \nNone\n from visitor method. In this case\nthe parent visitor method will not get this node in its \nchildren\n parameter.\n\n\nIn the \ncalc.py\nexample\n\na semantic analysis\n(\nCalcVisitor\n\nclass) will evaluate the result of arithmetic expression. The parse tree is thus\ntransformed to a single numeric value that represent the result of the\nexpression.\n\n\nIn the \nrobot.py\nexample\n a\nsemantic analysis\n(\nRobotVisitor\n\nclass) will evaluate robot program (transform its parse tree) to the final robot\nlocation.\n\n\nSemantic analysis can do a complex stuff. For example, see\n\npeg_peg.py\n\nand\n\nPEGVisitor\n\nclass where the PEG parser for the given language is built using semantic\nanalysis.\n\n\nSemanticActionResults\n\n\nClass of object returned from the parse tree nodes evaluation. Used for\nfiltering and navigation over evaluation results on children nodes.\n\n\nInstance of this class is given as \nchildren\n parameter of \nvisitor_xxx\n\nmethods.  This class inherits \nlist\n so index access as well as iteration is\navailable.\n\n\nFurthermore, child nodes can be filtered by rule name using name lookup.\n\n\ndef visit_bar(self, node, children):\n  # Index access\n  child = children[2]\n\n  # Iteration\n  for child in children:\n    ...\n\n  # Rule name lookup\n  # Returns a list of all rules created by PEG rule 'baz'\n  baz_created = children['baz']\n\n\n\n\nPost-processing in second calls\n\n\nVisitor may define method with the \nsecond_<rule_name>\n name form. If this\nmethod exists it will be called after all parse tree node are processed and it\nwill be given the results of the \nvisit_<rule_name>\n call.\n\n\nThis is usually used when some additional post-processing is needed (e.g.\nreference resolving).\n\n\nDefault actions\n\n\nFor each parse tree node that does not have an appropriate \nvisit_xxx\n method a\ndefault action is performed. If the node is created by a plain string match\naction will return \nNone\n and thus suppress this node. This is handy for all\nthose syntax noise tokens (brackets, braces, keywords etc.).\n\n\nFor example, if your grammar is:\n\n\nnumber_in_brackets = \"(\" number \")\"\nnumber = r'\\d+'\n\n\n\n\nthen the default action for \nnumber\n will return number node converted to\na string and the default action for \n(\n and \n)\n will return \nNone\n and thus\nsuppress these nodes so the visitor method for \nnumber_in_brackets\n rule will\nonly see one child (from the \nnumber\n rule reference).\n\n\nIf the node is a non-terminal and there is only one child the default action\nwill return that child effectively passing it to the parent node visitor.\n\n\nDefault actions can be disabled by setting parameter \ndefaults\n to \nFalse\n on\nvisitor construction.\n\n\nresult = visit_parse_tree(parse_tree, CalcVisitor(defaults=False))\n\n\n\n\nIf you want to call this default behaviour from your visitor method call\n\nvisit__default__(node, children)\n on superclass (\nPTNodeVisitor\n).\n\n\ndef visitor_myrule(self, node, children):\n  if some_condition:\n    ...\n  else:\n    return super(MyVisitor, self).visit__default__(node, children)",
            "title": "Semantic analysis"
        },
        {
            "location": "/semantics/#semantic-analysis-visitors",
            "text": "This section explains how to transform parse tree to a more usable structure.   You will surely always want to extract some information from the parse tree or\nto transform it in some more usable form.  The process of parse tree\ntransformation to other forms is referred to as  semantic analysis .  You could\ndo that using parse tree navigation etc. but it is better to use some standard\nmechanism.  In Arpeggio a visitor pattern is used for semantic analysis. You write a python\nclass that inherits  PTNodeVisitor  and has a methods of the form visit_<rule name>(self, node, children)  where rule name is a rule name from\nthe grammar.  class CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        return float(node.value)\n\n    def visit_factor(self, node, children):\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]\n\n    ...  During a semantic analysis a parse tree is walked in the depth-first manner and\nfor each node a proper visitor method is called to transform it to some other\nform. The results are than fed to the parent node visitor method.  This is\nrepeated until the final, top level parse tree node is processed (its visitor is\ncalled). The result of the top level node is the final output of the semantic\nanalysis.  To run semantic analysis apply your visitor class to the parse tree using visit_parse_tree  function.  result = visit_parse_tree(parse_tree, CalcVisitor(debug=True))  The first parameter is a parse tree you get from the  parser.parse  call while\nthe second parameter is an instance of your visitor class. Semantic analysis can\nbe run in debug mode if you set  debug  parameter to  True  during visitor\nconstruction. You can use this flag to print your own debug information from\nvisitor methods.  class MyLanguageVisitor(PTNodeVisitor):\n\n  def visit_somerule(self, node, children):\n    if self.debug:\n      print(\"Visiting some rule!\")  During semantic analysis, each  visitor_xxx  method gets current parse tree node\nas the  node  parameter and the evaluated children nodes as the  children \nparameter.  For example, if you have  expression  rule in your grammar than the\ntransformation of the non-terminal matched by this rule can be done as:  def visitor_expression(self, node, children):\n  ... # transform node using 'node' and 'children' parameter\n  return transformed_node  node  is the current  NonTerminal  or  Terminal  from the parse tree while the children  is an instance of  SemanticActionResults  class. This class is a\nlist-like structure that holds the results of semantic evaluation from the\nchildren parse tree nodes (analysis is done bottom-up).  To suppress node completely return  None  from visitor method. In this case\nthe parent visitor method will not get this node in its  children  parameter.  In the  calc.py\nexample \na semantic analysis\n( CalcVisitor \nclass) will evaluate the result of arithmetic expression. The parse tree is thus\ntransformed to a single numeric value that represent the result of the\nexpression.  In the  robot.py\nexample  a\nsemantic analysis\n( RobotVisitor \nclass) will evaluate robot program (transform its parse tree) to the final robot\nlocation.  Semantic analysis can do a complex stuff. For example, see peg_peg.py \nand PEGVisitor \nclass where the PEG parser for the given language is built using semantic\nanalysis.",
            "title": "Semantic analysis - Visitors"
        },
        {
            "location": "/semantics/#semanticactionresults",
            "text": "Class of object returned from the parse tree nodes evaluation. Used for\nfiltering and navigation over evaluation results on children nodes.  Instance of this class is given as  children  parameter of  visitor_xxx \nmethods.  This class inherits  list  so index access as well as iteration is\navailable.  Furthermore, child nodes can be filtered by rule name using name lookup.  def visit_bar(self, node, children):\n  # Index access\n  child = children[2]\n\n  # Iteration\n  for child in children:\n    ...\n\n  # Rule name lookup\n  # Returns a list of all rules created by PEG rule 'baz'\n  baz_created = children['baz']",
            "title": "SemanticActionResults"
        },
        {
            "location": "/semantics/#post-processing-in-second-calls",
            "text": "Visitor may define method with the  second_<rule_name>  name form. If this\nmethod exists it will be called after all parse tree node are processed and it\nwill be given the results of the  visit_<rule_name>  call.  This is usually used when some additional post-processing is needed (e.g.\nreference resolving).",
            "title": "Post-processing in second calls"
        },
        {
            "location": "/semantics/#default-actions",
            "text": "For each parse tree node that does not have an appropriate  visit_xxx  method a\ndefault action is performed. If the node is created by a plain string match\naction will return  None  and thus suppress this node. This is handy for all\nthose syntax noise tokens (brackets, braces, keywords etc.).  For example, if your grammar is:  number_in_brackets = \"(\" number \")\"\nnumber = r'\\d+'  then the default action for  number  will return number node converted to\na string and the default action for  (  and  )  will return  None  and thus\nsuppress these nodes so the visitor method for  number_in_brackets  rule will\nonly see one child (from the  number  rule reference).  If the node is a non-terminal and there is only one child the default action\nwill return that child effectively passing it to the parent node visitor.  Default actions can be disabled by setting parameter  defaults  to  False  on\nvisitor construction.  result = visit_parse_tree(parse_tree, CalcVisitor(defaults=False))  If you want to call this default behaviour from your visitor method call visit__default__(node, children)  on superclass ( PTNodeVisitor ).  def visitor_myrule(self, node, children):\n  if some_condition:\n    ...\n  else:\n    return super(MyVisitor, self).visit__default__(node, children)",
            "title": "Default actions"
        },
        {
            "location": "/troubleshooting/",
            "text": "Troubleshooting Guide\n\n\nCommon problems and mistakes\n\n\n\n\nLeft recursion and RecursionError\n\n\nIf you get \nRecursionError: maximum recursion depth exceeded while calling a\nPython object\n it is a good indication that you have a \nleft\nrecursion\n in the grammar.\n\n\n\n\nNote\n\n\nArpeggio parser will implement a support for detecting and reporting of left\nrecursions in the grammar. See \nissue\n23\n\n\n\n\nA left recursion is found if the parser calls the same rule again while no\ncharacters from the input is consumed from the previous call (e.g. we have the\nsame state). This will lead to the same sequence of events and we have infinite\nloop.\n\n\nFor example, lets suppose that we want to match following string:\n\n\nb a a a a a a\n\n\n\nWe could write a grammar like this:\n\n\nA = A 'a' / 'b'\n\n\n\nBut this grammar is left-recursive and the recursive-descent top-down parser\nlike Arpeggio will try to loop indefinitely trying to match \nA\n over and over\nagain in the same spot of the input string.\n\n\nAlthough, there are techniques to handle left-recursion in top-down parsers\nautomatically, Arpeggio does not implements them and a classic approach of\n\nremoving left\nrecursion\n\nmust be used.\n\n\nTo remove left recursion from the above grammar we do the following:\n\n\nA = 'b' 'a'*\n\n\n\nOr, get all non-left recursive choices and put them first (\nb\n in this case) and\nthan add the zero-or-more repetition of the recursive part without the left\nrecursive non-terminal (\na\n from \nA 'a'\n in this case).\n\n\nAnother example:\n\n\nadd = mult / add '+' mult / add '-' mult\n\n\n\nbecomes:\n\n\nadd = mult (('+' mult) / ('-' mult))*\n\n\n\nor:\n\n\nadd = mult (('+' / '-') mult)*\n\n\n\nIn general:\n\n\nA = A a1 / A a2 / ... / A an / b1 / b2 / ... / bm\n\n\n\nwhere uppercase letters represents non-terminals whereas lowercase letters\nrepresent terminals.\n\n\nRemoving left recursion yields:\n\n\nA = (b1 / b2 / ... / bm) (a1 / a2 / ... / an)*\n\n\n\n\n\nDanger\n\n\nBe aware that the parse tree will not be the same.\n\n\n\n\nUnrecognized grammar element '...'\n\n\nThis might happen when non-unicode literals are used. Make sure that you use\nunicode literals when defining grammars using Python notation.\n\n\nYou might want to include:\n\n\nfrom __future__ import unicode_literals\n\n\n\n\nThis will enable unicode literals in the python < 3.\n\n\nVisitor method is not called during semantic analysis\n\n\nSemantic analysis operates on a parse tree nodes produced by grammar rules.\nIf you are using a \nreduce_tree=True\n option in the construction of the parser\nall non-terminal nodes with only one child will be suppressed in the parse tree.\nThus, visitor methods for those nodes will not be called.\n\n\nTo resolve issue either disable tree reduction during parser construction (i.e.\n\nreduce_tree=False\n) or do visitor job in some of the calling rules that produce\nparse tree node with more than one child.\n\n\nAs a side note, there is implicit reduction of nodes whose grammar rule is a \nsequence with only one child.\n\n\ndef mean():             return number\ndef number():           return _(r'\\d*\\.\\d*|\\d+')\n\n\n\n\nHere a node \nnumber\n will be suppressed from the parser model and visitor\n\nvisit_number\n will not be called. You have to define \nvisit_mean\n or a visitor\nfor some of the rules calling \nmean\n.\n\n\nThis implicit reduction can not be disabled at the moment. Please see \nissue\n24\n.",
            "title": "Troubleshooting"
        },
        {
            "location": "/troubleshooting/#troubleshooting-guide",
            "text": "Common problems and mistakes",
            "title": "Troubleshooting Guide"
        },
        {
            "location": "/troubleshooting/#left-recursion-and-recursionerror",
            "text": "If you get  RecursionError: maximum recursion depth exceeded while calling a\nPython object  it is a good indication that you have a  left\nrecursion  in the grammar.   Note  Arpeggio parser will implement a support for detecting and reporting of left\nrecursions in the grammar. See  issue\n23   A left recursion is found if the parser calls the same rule again while no\ncharacters from the input is consumed from the previous call (e.g. we have the\nsame state). This will lead to the same sequence of events and we have infinite\nloop.  For example, lets suppose that we want to match following string:  b a a a a a a  We could write a grammar like this:  A = A 'a' / 'b'  But this grammar is left-recursive and the recursive-descent top-down parser\nlike Arpeggio will try to loop indefinitely trying to match  A  over and over\nagain in the same spot of the input string.  Although, there are techniques to handle left-recursion in top-down parsers\nautomatically, Arpeggio does not implements them and a classic approach of removing left\nrecursion \nmust be used.  To remove left recursion from the above grammar we do the following:  A = 'b' 'a'*  Or, get all non-left recursive choices and put them first ( b  in this case) and\nthan add the zero-or-more repetition of the recursive part without the left\nrecursive non-terminal ( a  from  A 'a'  in this case).  Another example:  add = mult / add '+' mult / add '-' mult  becomes:  add = mult (('+' mult) / ('-' mult))*  or:  add = mult (('+' / '-') mult)*  In general:  A = A a1 / A a2 / ... / A an / b1 / b2 / ... / bm  where uppercase letters represents non-terminals whereas lowercase letters\nrepresent terminals.  Removing left recursion yields:  A = (b1 / b2 / ... / bm) (a1 / a2 / ... / an)*   Danger  Be aware that the parse tree will not be the same.",
            "title": "Left recursion and RecursionError"
        },
        {
            "location": "/troubleshooting/#unrecognized-grammar-element",
            "text": "This might happen when non-unicode literals are used. Make sure that you use\nunicode literals when defining grammars using Python notation.  You might want to include:  from __future__ import unicode_literals  This will enable unicode literals in the python < 3.",
            "title": "Unrecognized grammar element '...'"
        },
        {
            "location": "/troubleshooting/#visitor-method-is-not-called-during-semantic-analysis",
            "text": "Semantic analysis operates on a parse tree nodes produced by grammar rules.\nIf you are using a  reduce_tree=True  option in the construction of the parser\nall non-terminal nodes with only one child will be suppressed in the parse tree.\nThus, visitor methods for those nodes will not be called.  To resolve issue either disable tree reduction during parser construction (i.e. reduce_tree=False ) or do visitor job in some of the calling rules that produce\nparse tree node with more than one child.  As a side note, there is implicit reduction of nodes whose grammar rule is a \nsequence with only one child.  def mean():             return number\ndef number():           return _(r'\\d*\\.\\d*|\\d+')  Here a node  number  will be suppressed from the parser model and visitor visit_number  will not be called. You have to define  visit_mean  or a visitor\nfor some of the rules calling  mean .  This implicit reduction can not be disabled at the moment. Please see  issue\n24 .",
            "title": "Visitor method is not called during semantic analysis"
        },
        {
            "location": "/tutorials/csv/",
            "text": "Comma-Separated Values (CSV) parser tutorial\n\n\nA tutorial for building parser for well known CSV format.\n\n\n\n\nIn this tutorial we will see how to make a parser for a simple data interchange\nformat - \nCSV\n (Comma-Separated Values).\nCSV is a textual format for tabular data interchange. It is described by\n\nRFC 4180\n.\n\n\nHere\n is an example of\nCSV file:\n\n\nYear,Make,Model,Length\n1997,Ford,E350,2.34\n2000,Mercury,Cougar,2.38\n\n\n\n\nAlthough, there is \ncsv module\n in\nthe standard Python library this example has been made as the CSV is ubiquitous\nand easy to understand so it it a good starter for learning Arpeggio.\n\n\nThe grammar\n\n\nLet's start first by creating a python module called \ncsv.py\n.\n\n\nNow, let's define CSV grammar. \n\n\n\n\n\n\nCSV file consists of one or more records or newlines and the End-Of-File at the\n  end. Python list inside \nOneOrMore\n will be interpreted as \nOrdered\n  Choice\n.\n\n\ndef csvfile():    return OneOrMore([record, '\\n']), EOF\n\n\n\n\n\n\n\nEach record consists of fields separated with commas.\n\n\ndef record():     return field, ZeroOrMore(\",\", field)\n\n\n\n\n\n\n\nEach field may be quoted or not.\n\n\ndef field():      return [quoted_field, field_content]\n\n\n\n\n\n\n\nField content is everything until newline or comma.\n\n\ndef field_content():            return _(r'([^,\\n])+')\n\n\n\nWe use regular expression to match everything that is not comma or\n  newline.\n\n\n\n\n\n\nQuoted field starts and ends with double quotes.\n\n\ndef quoted_field():             return '\"', field_content_quoted, '\"'\n\n\n\n\n\n\n\nQuoted field content is defined as \n\n\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\n\n\n\nQuoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it (\n\"\"\n).\n\n\n\n\n\n\nThe whole content of the \ncsv.py\n file until now should be:\n\n\nfrom arpeggio import *\nfrom arpeggio import RegExMatch as _\n\n# This is the CSV grammar\ndef record():                   return field, ZeroOrMore(\",\", field)\ndef field():                    return [quoted_field, field_content]\ndef quoted_field():             return '\"', field_content_quoted, '\"'\ndef field_content():            return _(r'([^,\\n])+')\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\ndef csvfile():                  return OneOrMore([record, '\\n']), EOF\n\n\n\nThe parser\n\n\nLet's instantiate parser. In order to catch newlines in \ncsvfile\n rule we must\ntell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them.\nThus, we will be able to handle them explicitly as we do in csvfile rule. To do\nso we will use \nws\n parameter in parser construction to redefine what is\nconsidered as whitespace.  You can find more information\n\nhere\n.\n\n\nAfter the grammar in \ncsv.py\n instantiate the parser:\n\n\nparser = ParserPython(csvfile, ws='\\t ')\n\n\n\nSo, whitespace will be a tab char or a space. Newline will be treated as regular\ncharacter.  We give grammar root rule to the \nParserPython\n. In this example it\nis \ncsvfile\n function.\n\n\nparser\n now refers to the parser object capable of parsing CSV inputs.\n\n\nParsing\n\n\nLet's parse some CSV example string.\n\n\nCreate file \ntest_data.csv\n with the following content:\n\n\nUnquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\"\n\nUnquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"34312.7\"\nUnquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343486.12\"\n\n\n\nIn \ncsv.py\n file write:\n\n\ntest_data = open('test_data.csv', 'r').read()\nparse_tree = parser.parse(test_data)\n\n\n\n\n\ntest_data\n is Python string containing test CSV data from the file. Calling\n\nparser.parse\n on the data will produce the \nparse tree\n.\n\n\nIf you run \ncsv.py\n module, and there are no syntax errors in the \ntest_data.csv\n\nfile, \nparse_tree\n will be a reference to \nparse tree\n of\nthe test CSV data.\n\n\n$ python csv.py\n\n\n\n\nCongratulations!! You have successfuly parsed CSV file.\n\n\nThis parse tree is \nvisualized\n below (Tip: The\nimage is large. Click on it to see it in a separate tab and to be able to use\nzooming):\n\n\n\n\n\n\nNote\n\n\nTo visualize grammar (aka parser model) and parse tree instantiate the\nparser in debug mode.\n\n\nparser = ParserPython(csvfile, ws='\\t ', debug=True)\n\n\n\nTransform generated \ndot\n files to images.\nSee more \nhere\n\n\n\n\nDefining grammar using PEG notation\n\n\nNow, let's try the same but using \ntextual PEG\nnotation\n for the grammar\ndefinition.\n\n\nWe shall repeat the process above but we shall encode rules in PEG.\nWe shall use clean PEG variant (\narpeggio.cleanpeg\n module).\n\n\nFirst, create textual file \ncsv.peg\n to store the grammar.\n\n\n\n\n\n\nCSV file consists of one or more records or newlines and the End-Of-File at\n  the end.\n\n\ncsvfile = (record / '\\n')+ EOF\n\n\n\n\n\n\n\nEach record consists of fields separated with commas.\n\n\nrecord = field (\",\" field)*\n\n\n\n\n\n\n\nEach field may be quoted or not.\n\n\nfield = quoted_field / field_content\n\n\n\n\n\n\n\nField content is everything until newline or comma.\n\n\nfield_content = r'([^,\\n])+'\n\n\n\nWe use regular expression to match everything that is not comma or\n  newline.\n\n\n\n\n\n\nQuoted field starts and ends with double quotes.\n\n\nquoted_field = '\"' field_content_quoted '\"'\n\n\n\n\n\n\n\nQuoted field content is defined as \n\n\nfield_content_quoted = r'((\"\")|([^\"]))+'\n\n\n\nQuoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it (\n\"\"\n).\n\n\n\n\n\n\nThe whole grammar (i.e. the contents of \ncsv.peg\n file) is:\n\n\n  csvfile = (record / r'\\n')+ EOF\n  record = field (\",\" field)*\n  field = quoted_field / field_content\n  field_content = r'([^,\\n])+'\n  quoted_field = '\"' field_content_quoted '\"'\n  field_content_quoted = r'((\"\")|([^\"]))+'\n\n\n\nNow, we shall create \ncsv_peg.py\n file in order to instantiate our parser and\nparse inputs.  This time we shall instantiate different parser class\n(\nParserPEG\n). The whole content of \ncsv_peg.py\n should be:\n\n\nfrom arpeggio.cleanpeg import ParserPEG\n\ncsv_grammar = open('csv.peg', 'r').read()\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ')\n\n\n\n\nHere we load the grammar from \ncsv.peg\n file and construct the parser using\n\nParserPEG\n class.\n\n\nThe rest of the code is the same as in \ncsv.py\n. We load \ntest_data.csv\n and\ncall \nparser.parse\n on it to produce parse tree.\n\n\nTo verify that everything works without errors execute \ncsv_peg.py\n module.\n\n\n$ python csv_peg.py\n\n\n\n\nIf we put the parser in debug mode and generate parse tree image we can \nverify that we are getting the same parse tree regardless of the grammar\nspecification approach we use.\n\n\nTo put parser in debug mode add \ndebug=True\n to the parser parameters list.\n\n\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True)\n\n\n\n\nExtract data\n\n\nOur main goal is to extract data from the \ncsv\n file.\n\n\nThe parse tree we get as a result of parsing is not very useful on its own.\nWe need to transform it to some other data structure that we can use.\n\n\nFirst lets define our target data structure we want to get.\n\n\nSince \ncsv\n consists of list of records where each record consists of fields\nwe shall construct python list of lists:\n\n\n  [\n    [field1, field2, field3, ...],  # First row\n    [field1, field2, field3,...],   # Second row\n    [...],  # ...\n    ...\n  ]\n\n\n\nTo construct this list of list we may process parse tree by navigating its\nnodes and building the required target data structure.\nBut, it is easier to use Arpeggio's support for \nsemantic analysis - Visitor\nPattern\n.\n\n\nLet's make a Visitor for CSV that will build our list of lists.\n\n\nclass CSVVisitor(PTNodeVisitor):\n    def visit_record(self, node, children):\n        # record is a list of fields. The children nodes are fields so just\n        # transform it to python list.\n        return list(children)\n\n    def visit_csvfile(self, node, children):\n        # We are not interested in empty lines so we will filter them.\n        return [x for x in children if x!='\\n']\n\n\n\n\nand apply this visitor to the parse tree:\n\n\ncsv_content = visit_parse_tree(parse_tree, CSVVisitor())\n\n\n\n\nNow if we pretty-print \ncsv_content\n we can see that it is exactly what we wanted:\n\n\n[   [   u'Unquoted test',\n        u'Quoted test',\n        u'23234',\n        u'One Two Three',\n        u'343456.45'],\n    [   u'Unquoted test 2',\n        u'Quoted test with \"\"inner\"\" quotes',\n        u'23234',\n        u'One Two Three',\n        u'34312.7'],\n    [   u'Unquoted test 3',\n        u'Quoted test 3',\n        u'23234',\n        u'One Two Three',\n        u'343486.12']]\n\n\n\n\nBut, there is more we can do. If we look at our data we can see that some fields\nare of numeric type but they end up as strings in our target structure. Let's\nconvert them to Python floats or ints.  To do this conversion we will introduce\n\nvisit_field\n method in our \nCSVVisitor\n class.\n\n\nclass CSVVisitor(PTNodeVisitor):\n  ...\n  def visit_field(self, node, children):\n      value = children[0]\n      try:\n          return float(value)\n      except:\n          pass\n      try:\n          return int(value)\n      except:\n          return value\n  ...\n\n\n\n\nIf we pretty-print \ncsv_content\n now we can see that numeric values are not strings\nanymore but a proper Python types.\n\n\n[   [u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45],\n    [   u'Unquoted test 2',\n        u'Quoted test with \"\"inner\"\" quotes',\n        23234.0,\n        u'One Two Three',\n        34312.7],\n    [   u'Unquoted test 3',\n        u'Quoted test 3',\n        23234.0,\n        u'One Two Three',\n        343486.12]]\n\n\n\n\nThis example code can be found \nhere\n.",
            "title": "CSV"
        },
        {
            "location": "/tutorials/csv/#comma-separated-values-csv-parser-tutorial",
            "text": "A tutorial for building parser for well known CSV format.   In this tutorial we will see how to make a parser for a simple data interchange\nformat -  CSV  (Comma-Separated Values).\nCSV is a textual format for tabular data interchange. It is described by RFC 4180 .  Here  is an example of\nCSV file:  Year,Make,Model,Length\n1997,Ford,E350,2.34\n2000,Mercury,Cougar,2.38  Although, there is  csv module  in\nthe standard Python library this example has been made as the CSV is ubiquitous\nand easy to understand so it it a good starter for learning Arpeggio.",
            "title": "Comma-Separated Values (CSV) parser tutorial"
        },
        {
            "location": "/tutorials/csv/#the-grammar",
            "text": "Let's start first by creating a python module called  csv.py .  Now, let's define CSV grammar.     CSV file consists of one or more records or newlines and the End-Of-File at the\n  end. Python list inside  OneOrMore  will be interpreted as  Ordered\n  Choice .  def csvfile():    return OneOrMore([record, '\\n']), EOF    Each record consists of fields separated with commas.  def record():     return field, ZeroOrMore(\",\", field)    Each field may be quoted or not.  def field():      return [quoted_field, field_content]    Field content is everything until newline or comma.  def field_content():            return _(r'([^,\\n])+')  We use regular expression to match everything that is not comma or\n  newline.    Quoted field starts and ends with double quotes.  def quoted_field():             return '\"', field_content_quoted, '\"'    Quoted field content is defined as   def field_content_quoted():     return _(r'((\"\")|([^\"]))+')  Quoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it ( \"\" ).    The whole content of the  csv.py  file until now should be:  from arpeggio import *\nfrom arpeggio import RegExMatch as _\n\n# This is the CSV grammar\ndef record():                   return field, ZeroOrMore(\",\", field)\ndef field():                    return [quoted_field, field_content]\ndef quoted_field():             return '\"', field_content_quoted, '\"'\ndef field_content():            return _(r'([^,\\n])+')\ndef field_content_quoted():     return _(r'((\"\")|([^\"]))+')\ndef csvfile():                  return OneOrMore([record, '\\n']), EOF",
            "title": "The grammar"
        },
        {
            "location": "/tutorials/csv/#the-parser",
            "text": "Let's instantiate parser. In order to catch newlines in  csvfile  rule we must\ntell Arpeggio not to treat newlines as whitespace, i.e. not to skip over them.\nThus, we will be able to handle them explicitly as we do in csvfile rule. To do\nso we will use  ws  parameter in parser construction to redefine what is\nconsidered as whitespace.  You can find more information here .  After the grammar in  csv.py  instantiate the parser:  parser = ParserPython(csvfile, ws='\\t ')  So, whitespace will be a tab char or a space. Newline will be treated as regular\ncharacter.  We give grammar root rule to the  ParserPython . In this example it\nis  csvfile  function.  parser  now refers to the parser object capable of parsing CSV inputs.",
            "title": "The parser"
        },
        {
            "location": "/tutorials/csv/#parsing",
            "text": "Let's parse some CSV example string.  Create file  test_data.csv  with the following content:  Unquoted test, \"Quoted test\", 23234, One Two Three, \"343456.45\"\n\nUnquoted test 2, \"Quoted test with \"\"inner\"\" quotes\", 23234, One Two Three, \"34312.7\"\nUnquoted test 3, \"Quoted test 3\", 23234, One Two Three, \"343486.12\"  In  csv.py  file write:  test_data = open('test_data.csv', 'r').read()\nparse_tree = parser.parse(test_data)  test_data  is Python string containing test CSV data from the file. Calling parser.parse  on the data will produce the  parse tree .  If you run  csv.py  module, and there are no syntax errors in the  test_data.csv \nfile,  parse_tree  will be a reference to  parse tree  of\nthe test CSV data.  $ python csv.py  Congratulations!! You have successfuly parsed CSV file.  This parse tree is  visualized  below (Tip: The\nimage is large. Click on it to see it in a separate tab and to be able to use\nzooming):    Note  To visualize grammar (aka parser model) and parse tree instantiate the\nparser in debug mode.  parser = ParserPython(csvfile, ws='\\t ', debug=True)  Transform generated  dot  files to images.\nSee more  here",
            "title": "Parsing"
        },
        {
            "location": "/tutorials/csv/#defining-grammar-using-peg-notation",
            "text": "Now, let's try the same but using  textual PEG\nnotation  for the grammar\ndefinition.  We shall repeat the process above but we shall encode rules in PEG.\nWe shall use clean PEG variant ( arpeggio.cleanpeg  module).  First, create textual file  csv.peg  to store the grammar.    CSV file consists of one or more records or newlines and the End-Of-File at\n  the end.  csvfile = (record / '\\n')+ EOF    Each record consists of fields separated with commas.  record = field (\",\" field)*    Each field may be quoted or not.  field = quoted_field / field_content    Field content is everything until newline or comma.  field_content = r'([^,\\n])+'  We use regular expression to match everything that is not comma or\n  newline.    Quoted field starts and ends with double quotes.  quoted_field = '\"' field_content_quoted '\"'    Quoted field content is defined as   field_content_quoted = r'((\"\")|([^\"]))+'  Quoted field content is defined with regular expression that will match\n  everything until the closing double-quote. Double quote inside data must\n  be escaped by doubling it ( \"\" ).    The whole grammar (i.e. the contents of  csv.peg  file) is:    csvfile = (record / r'\\n')+ EOF\n  record = field (\",\" field)*\n  field = quoted_field / field_content\n  field_content = r'([^,\\n])+'\n  quoted_field = '\"' field_content_quoted '\"'\n  field_content_quoted = r'((\"\")|([^\"]))+'  Now, we shall create  csv_peg.py  file in order to instantiate our parser and\nparse inputs.  This time we shall instantiate different parser class\n( ParserPEG ). The whole content of  csv_peg.py  should be:  from arpeggio.cleanpeg import ParserPEG\n\ncsv_grammar = open('csv.peg', 'r').read()\nparser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ')  Here we load the grammar from  csv.peg  file and construct the parser using ParserPEG  class.  The rest of the code is the same as in  csv.py . We load  test_data.csv  and\ncall  parser.parse  on it to produce parse tree.  To verify that everything works without errors execute  csv_peg.py  module.  $ python csv_peg.py  If we put the parser in debug mode and generate parse tree image we can \nverify that we are getting the same parse tree regardless of the grammar\nspecification approach we use.  To put parser in debug mode add  debug=True  to the parser parameters list.  parser = ParserPEG(csv_grammar, 'csvfile', ws='\\t ', debug=True)",
            "title": "Defining grammar using PEG notation"
        },
        {
            "location": "/tutorials/csv/#extract-data",
            "text": "Our main goal is to extract data from the  csv  file.  The parse tree we get as a result of parsing is not very useful on its own.\nWe need to transform it to some other data structure that we can use.  First lets define our target data structure we want to get.  Since  csv  consists of list of records where each record consists of fields\nwe shall construct python list of lists:    [\n    [field1, field2, field3, ...],  # First row\n    [field1, field2, field3,...],   # Second row\n    [...],  # ...\n    ...\n  ]  To construct this list of list we may process parse tree by navigating its\nnodes and building the required target data structure.\nBut, it is easier to use Arpeggio's support for  semantic analysis - Visitor\nPattern .  Let's make a Visitor for CSV that will build our list of lists.  class CSVVisitor(PTNodeVisitor):\n    def visit_record(self, node, children):\n        # record is a list of fields. The children nodes are fields so just\n        # transform it to python list.\n        return list(children)\n\n    def visit_csvfile(self, node, children):\n        # We are not interested in empty lines so we will filter them.\n        return [x for x in children if x!='\\n']  and apply this visitor to the parse tree:  csv_content = visit_parse_tree(parse_tree, CSVVisitor())  Now if we pretty-print  csv_content  we can see that it is exactly what we wanted:  [   [   u'Unquoted test',\n        u'Quoted test',\n        u'23234',\n        u'One Two Three',\n        u'343456.45'],\n    [   u'Unquoted test 2',\n        u'Quoted test with \"\"inner\"\" quotes',\n        u'23234',\n        u'One Two Three',\n        u'34312.7'],\n    [   u'Unquoted test 3',\n        u'Quoted test 3',\n        u'23234',\n        u'One Two Three',\n        u'343486.12']]  But, there is more we can do. If we look at our data we can see that some fields\nare of numeric type but they end up as strings in our target structure. Let's\nconvert them to Python floats or ints.  To do this conversion we will introduce visit_field  method in our  CSVVisitor  class.  class CSVVisitor(PTNodeVisitor):\n  ...\n  def visit_field(self, node, children):\n      value = children[0]\n      try:\n          return float(value)\n      except:\n          pass\n      try:\n          return int(value)\n      except:\n          return value\n  ...  If we pretty-print  csv_content  now we can see that numeric values are not strings\nanymore but a proper Python types.  [   [u'Unquoted test', u'Quoted test', 23234.0, u'One Two Three', 343456.45],\n    [   u'Unquoted test 2',\n        u'Quoted test with \"\"inner\"\" quotes',\n        23234.0,\n        u'One Two Three',\n        34312.7],\n    [   u'Unquoted test 3',\n        u'Quoted test 3',\n        23234.0,\n        u'One Two Three',\n        343486.12]]  This example code can be found  here .",
            "title": "Extract data"
        },
        {
            "location": "/tutorials/bibtex/",
            "text": "BibTeX tutorial\n\n\nA tutorial for parsing well known format for bibliographic references.\n\n\n\n\nThe word \nBibTeX\n stands for a tool and a file format\nwhich are used to describe and process lists of references, mostly in\nconjunction with LaTeX documents.\n\n\nAn example of BibTeX entry is given below.\n\n\n@article{DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010,\n    author = \"Igor Dejanovi\\'{c} and Gordana Milosavljevi\\'{c} and Branko Peri\\v{s}i\\'{c} and Maja Tumbas\",\n    title = \"A {D}omain-Specific Language for Defining Static Structure of Database Applications\",\n    journal = \"Computer Science and Information Systems\",\n    year = \"2010\",\n    volume = \"7\",\n    pages = \"409--440\",\n    number = \"3\",\n    month = \"June\",\n    issn = \"1820-0214\",\n    doi = \"10.2298/CSIS090203002D\",\n    url = \"http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm\",\n    type = \"M23\"\n}\n\n\n\n\nEach BibTeX entry starts with \n@\n and a keyword denoting entry type (\narticle\n)\nin this example. After the entry type is the body of the reference inside curly\nbraces. The body of the reference consists of elements separated by a comma.\nThe first element is the key of the entry. It should be unique.\nThe rest of the entries are fields in the format:\n\n\n<field_name> = <field_value>\n\n\n\nThe grammar\n\n\nLet's start with the grammar.\nCreate file \nbibtex.py\n, and import \narpeggio\n.\n\n\nfrom arpeggio import *\nfrom arpeggio import RegExMatch as _\n\n\n\n\nThen create grammar rules:\n\n\n\n\nBibTeX file consists of zero or more BibTeX entries.\n\n\n\n\ndef bibfile():    return ZeroOrMore(bibentry), EOF\n\n\n\n\n\n\nNow we define the structure of BibTeX entry.\n\n\n\n\ndef bibentry():  return bibtype, \"{\", bibkey, \",\", field, ZeroOrMore(\",\", field), \"}\"\n\n\n\n\n\n\nEach field is given as field name, equals char (\n=\n), and the field value.\n\n\n\n\ndef field():     return fieldname, \"=\", fieldvalue\n\n\n\n\n\n\nField value can be specified inside braces or quotes.\n\n\n\n\ndef fieldvalue():               return [fieldvalue_braces, fieldvalue_quotes]\ndef fieldvalue_braces():        return \"{\", fieldvalue_braced_content, \"}\"\ndef fieldvalue_quotes():        return '\"', fieldvalue_quoted_content, '\"'\n\n\n\n\n\n\nNow, let's define field name, BibTeX type and the key. We use regular\n  expression match for this (\nRegExMatch\n class).\n\n\n\n\ndef fieldname():                return _(r'[-\\w]+')\ndef bibtype():                  return _(r'@\\w+')\ndef bibkey():                   return _(r'[^\\s,]+')\n\n\n\n\nField name is defined as hyphen or alphanumeric one or more times.\n  BibTeX entry type is \n@\n char after which must be one or more alphanumeric.\n  BibTeX key is everything until the first space or comma.\n\n\n\n\nField value can be quoted and braced. Let's match the content.\n\n\n\n\ndef fieldvalue_quoted_content():    return _(r'((\\\\\")|[^\"])*')\ndef fieldvalue_braced_content():    return Combine(ZeroOrMore(Optional(And(\"{\"), fieldvalue_inner),\\\n                                                  fieldvalue_part))\ndef fieldvalue_part():          return _(r'((\\\\\")|[^{}])+')\ndef fieldvalue_inner():         return \"{\", fieldvalue_braced_content, \"}\"\n\n\n\n\n\n\nCombine decorator\n\n\nWe use \nCombine\n decorator to specify braced content. This decorator\nproduces a \nTerminal\n node in \nthe parse\ntree\n.\n\n\n\n\nThe parser\n\n\nTo instantiate the parser we are using \nParserPython\n Arpeggio's class.\n\n\nparser = ParserPython(bibfile)\n\n\n\n\nNow, we have our parser. Let's parse some input:\n\n\n\n\nFirst load some BibTeX data from a file.\n\n\n\n\nfile_name = os.path.join(os.path.dirname(__file__), 'bibtex_example.bib')\nwith codecs.open(file_name, \"r\", encoding=\"utf-8\") as bibtexfile:\n    bibtexfile_content = bibtexfile.read()\n\n\n\n\nWe are using \ncodecs\n module to load the file using \nutf-8\n encoding.\n\nbibtexfile_content\n is now a string with the content of the file.\n\n\n\n\nParse the input string\n\n\n\n\nparse_tree = parser.parse(bibtexfile_content)\n\n\n\n\nThe parse tree is produced. \n\n\nExtracting data from the parse tree\n\n\nLet's suppose that we want our BibTeX file to be transformed to a list of\nPython dictionaries where each field is keyed by its name and the value is \nthe field value cleaned up from the BibTeX cruft.\n\n\nLike this:\n\n\n{   'author': 'Igor Dejanovi\u0107 and Gordana Milosavljevi\u0107 and Branko Peri\u0161i\u0107 and Maja Tumbas',\n    'bibkey': 'DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010',\n    'bibtype': '@article',\n    'doi': '10.2298/CSIS090203002D',\n    'issn': '1820-0214',\n    'journal': 'Computer Science and Information Systems',\n    'month': 'June',\n    'number': '3',\n    'pages': '409--440',\n    'title': 'A Domain-Specific Language for Defining Static Structure of Database Applications',\n    'type': 'M23',\n    'url': 'http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm',\n    'volume': '7',\n    'year': '2010'}\n\n\n\n\nThe key is stored under a dict key \nbibkey\n while the entry type is stored \nunder the dict key \nbibtype\n.\n\n\nAfter calling the \nparse\n method on the parser our textual data will be parsed\nand stored in \nthe parse tree\n. We could navigate the tree \nto extract the data and build the python list of dictionaries but a lot easier\nis to use \nArpeggio's visitor support\n.\n\n\nIn this case we shall create \nBibTeXVisitor\n class with \nvisit_*\n methods for\neach grammar rule whose parse tree node we want to process.\n\n\nclass BibTeXVisitor(PTNodeVisitor):\n\n    def visit_bibfile(self, node, children):\n        \"\"\"\n        Just returns list of child nodes (bibentries).\n        \"\"\"\n        # Return only dict nodes\n        return [x for x in children if type(x) is dict]\n\n    def visit_bibentry(self, node, children):\n        \"\"\"\n        Constructs a map where key is bibentry field name.\n        Key is returned under 'bibkey' key. Type is returned under 'bibtype'.\n        \"\"\"\n        bib_entry_map = {\n            'bibtype': children[0],\n            'bibkey': children[1]\n        }\n        for field in children[2:]:\n            bib_entry_map[field[0]] = field[1]\n        return bib_entry_map\n\n    def visit_field(self, node, children):\n        \"\"\"\n        Constructs a tuple (fieldname, fieldvalue).\n        \"\"\"\n        field = (children[0], children[1])\n        return field\n\n\n\n\nNow, apply the visitor to the parse tree.\n\n\nast = visit_parse_tree(parse_tree, BibTeXVisitor())\n\n\n\n\nast\n is now a Python list of dictionaries in the desired format from above.\n\n\nA full source code for this example can be found in \nthe source\ncode repository\n.  \n\n\n\n\nNote\n\n\nExample in the repository is actually a fully working parser with the\nsupport for BibTeX comments and comment entries. This is out of scope\nfor this tutorial. You can find the details in the source code.",
            "title": "BibTex"
        },
        {
            "location": "/tutorials/bibtex/#bibtex-tutorial",
            "text": "A tutorial for parsing well known format for bibliographic references.   The word  BibTeX  stands for a tool and a file format\nwhich are used to describe and process lists of references, mostly in\nconjunction with LaTeX documents.  An example of BibTeX entry is given below.  @article{DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010,\n    author = \"Igor Dejanovi\\'{c} and Gordana Milosavljevi\\'{c} and Branko Peri\\v{s}i\\'{c} and Maja Tumbas\",\n    title = \"A {D}omain-Specific Language for Defining Static Structure of Database Applications\",\n    journal = \"Computer Science and Information Systems\",\n    year = \"2010\",\n    volume = \"7\",\n    pages = \"409--440\",\n    number = \"3\",\n    month = \"June\",\n    issn = \"1820-0214\",\n    doi = \"10.2298/CSIS090203002D\",\n    url = \"http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm\",\n    type = \"M23\"\n}  Each BibTeX entry starts with  @  and a keyword denoting entry type ( article )\nin this example. After the entry type is the body of the reference inside curly\nbraces. The body of the reference consists of elements separated by a comma.\nThe first element is the key of the entry. It should be unique.\nThe rest of the entries are fields in the format:  <field_name> = <field_value>",
            "title": "BibTeX tutorial"
        },
        {
            "location": "/tutorials/bibtex/#the-grammar",
            "text": "Let's start with the grammar.\nCreate file  bibtex.py , and import  arpeggio .  from arpeggio import *\nfrom arpeggio import RegExMatch as _  Then create grammar rules:   BibTeX file consists of zero or more BibTeX entries.   def bibfile():    return ZeroOrMore(bibentry), EOF   Now we define the structure of BibTeX entry.   def bibentry():  return bibtype, \"{\", bibkey, \",\", field, ZeroOrMore(\",\", field), \"}\"   Each field is given as field name, equals char ( = ), and the field value.   def field():     return fieldname, \"=\", fieldvalue   Field value can be specified inside braces or quotes.   def fieldvalue():               return [fieldvalue_braces, fieldvalue_quotes]\ndef fieldvalue_braces():        return \"{\", fieldvalue_braced_content, \"}\"\ndef fieldvalue_quotes():        return '\"', fieldvalue_quoted_content, '\"'   Now, let's define field name, BibTeX type and the key. We use regular\n  expression match for this ( RegExMatch  class).   def fieldname():                return _(r'[-\\w]+')\ndef bibtype():                  return _(r'@\\w+')\ndef bibkey():                   return _(r'[^\\s,]+')  Field name is defined as hyphen or alphanumeric one or more times.\n  BibTeX entry type is  @  char after which must be one or more alphanumeric.\n  BibTeX key is everything until the first space or comma.   Field value can be quoted and braced. Let's match the content.   def fieldvalue_quoted_content():    return _(r'((\\\\\")|[^\"])*')\ndef fieldvalue_braced_content():    return Combine(ZeroOrMore(Optional(And(\"{\"), fieldvalue_inner),\\\n                                                  fieldvalue_part))\ndef fieldvalue_part():          return _(r'((\\\\\")|[^{}])+')\ndef fieldvalue_inner():         return \"{\", fieldvalue_braced_content, \"}\"   Combine decorator  We use  Combine  decorator to specify braced content. This decorator\nproduces a  Terminal  node in  the parse\ntree .",
            "title": "The grammar"
        },
        {
            "location": "/tutorials/bibtex/#the-parser",
            "text": "To instantiate the parser we are using  ParserPython  Arpeggio's class.  parser = ParserPython(bibfile)  Now, we have our parser. Let's parse some input:   First load some BibTeX data from a file.   file_name = os.path.join(os.path.dirname(__file__), 'bibtex_example.bib')\nwith codecs.open(file_name, \"r\", encoding=\"utf-8\") as bibtexfile:\n    bibtexfile_content = bibtexfile.read()  We are using  codecs  module to load the file using  utf-8  encoding. bibtexfile_content  is now a string with the content of the file.   Parse the input string   parse_tree = parser.parse(bibtexfile_content)  The parse tree is produced.",
            "title": "The parser"
        },
        {
            "location": "/tutorials/bibtex/#extracting-data-from-the-parse-tree",
            "text": "Let's suppose that we want our BibTeX file to be transformed to a list of\nPython dictionaries where each field is keyed by its name and the value is \nthe field value cleaned up from the BibTeX cruft.  Like this:  {   'author': 'Igor Dejanovi\u0107 and Gordana Milosavljevi\u0107 and Branko Peri\u0161i\u0107 and Maja Tumbas',\n    'bibkey': 'DejanovicADomain-SpecificLanguageforDefiningStaticStructureofDatabaseApplications2010',\n    'bibtype': '@article',\n    'doi': '10.2298/CSIS090203002D',\n    'issn': '1820-0214',\n    'journal': 'Computer Science and Information Systems',\n    'month': 'June',\n    'number': '3',\n    'pages': '409--440',\n    'title': 'A Domain-Specific Language for Defining Static Structure of Database Applications',\n    'type': 'M23',\n    'url': 'http://www.comsis.org/ComSIS/Vol7No3/RegularPapers/paper2.htm',\n    'volume': '7',\n    'year': '2010'}  The key is stored under a dict key  bibkey  while the entry type is stored \nunder the dict key  bibtype .  After calling the  parse  method on the parser our textual data will be parsed\nand stored in  the parse tree . We could navigate the tree \nto extract the data and build the python list of dictionaries but a lot easier\nis to use  Arpeggio's visitor support .  In this case we shall create  BibTeXVisitor  class with  visit_*  methods for\neach grammar rule whose parse tree node we want to process.  class BibTeXVisitor(PTNodeVisitor):\n\n    def visit_bibfile(self, node, children):\n        \"\"\"\n        Just returns list of child nodes (bibentries).\n        \"\"\"\n        # Return only dict nodes\n        return [x for x in children if type(x) is dict]\n\n    def visit_bibentry(self, node, children):\n        \"\"\"\n        Constructs a map where key is bibentry field name.\n        Key is returned under 'bibkey' key. Type is returned under 'bibtype'.\n        \"\"\"\n        bib_entry_map = {\n            'bibtype': children[0],\n            'bibkey': children[1]\n        }\n        for field in children[2:]:\n            bib_entry_map[field[0]] = field[1]\n        return bib_entry_map\n\n    def visit_field(self, node, children):\n        \"\"\"\n        Constructs a tuple (fieldname, fieldvalue).\n        \"\"\"\n        field = (children[0], children[1])\n        return field  Now, apply the visitor to the parse tree.  ast = visit_parse_tree(parse_tree, BibTeXVisitor())  ast  is now a Python list of dictionaries in the desired format from above.  A full source code for this example can be found in  the source\ncode repository .     Note  Example in the repository is actually a fully working parser with the\nsupport for BibTeX comments and comment entries. This is out of scope\nfor this tutorial. You can find the details in the source code.",
            "title": "Extracting data from the parse tree"
        },
        {
            "location": "/tutorials/calc/",
            "text": "Calculator tutorial\n\n\nA tutorial for parsing and evaluation of arithmetic expressions.\n\n\n\n\nIn this tutorial we will make a parser and evaluator for simple arithmetic\nexpression (numbers and operations - addition, subtraction, multiplication and\ndivision).  The parser will be able to recognize and evaluate following\nexpressions:\n\n\n2+7-3.6\n3/(3-1)+45*2.17+8\n4*12+5-4*(2-8)\n...\n\n\n\nEvaluation will be done using \nsupport for semantic analysis\n.\n\n\nParsing infix expression has additional constraints related to operator\nprecedence. Arpeggio is recursive-descent parser, parsing the input from left to\nright and doing a leftmost derivation. \nThere is a simple technique that will enable proper evaluation in the context\nof a different operator precedence.\n\n\nLet's start with grammar definition.\n\n\nThe grammar\n\n\n\n\nEach \ncalc\n file consists of one or more expressions.\n\n\n\n\ndef calc():       return OneOrMore(expression), EOF\n\n\n\n\n\n\nEach expression is a sum or subtraction of terms.\n\n\n\n\ndef expression(): return term, ZeroOrMore([\"+\", \"-\"], term)\n\n\n\n\n\n\nEach term is a multiplication or division of factors.\n\n\n\n\ndef term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)\n\n\n\n\n\n\nNote\n\n\nNotice that the order of precendence is from lower to upper.\nThe deeper is the grammar rule, the tighter is the bonding.\n\n\n\n\n\n\nEach factor is either a number or an expression inside brackets. The prefix\n  sign is optional. This is a support for unary minus.\n\n\n\n\ndef factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]\n\n\n\n\n\n\nNote\n\n\nNotice indirect recursion here to \nexpression\n. It is not left since the\nopening bracket must be found.\n\n\n\n\n\n\nAnd finally we define \nnumber\n using regular expression as\n\n\n\n\ndef number():     return _(r'\\d*\\.\\d*|\\d+')\n\n\n\n\nThe parser\n\n\nUsing above grammar specified in \nPython\nnotation\n we instantiate the parser\nusing \nParserPython\n class.\n\n\n  parser = ParserPython(calc)\n\n\n\n\nThis parser is able to parse arithmetic expression like this\n\n\n-(4-1)*5+(2+4.67)+5.89/(.2+7)\n\n\n\n\nand produce parse tree like this\n\n\n\n\n\n\nNote\n\n\nAll tree images in this documentation are produced by running the parser\nin \ndebug mode\n and using \nvisualization\nsupport\n.\n\n\n\n\nThe parsing is done like this:\n\n\ninput_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)\n\n\n\n\nBy ordering operation in the grammar form lower to upper precendence we have\ngot the parse tree where the priority is retained. This will help us to easier\nmake an expression evaluation.\n\n\nEvaluating parse tree\n\n\nTo implement evaluation we shall use Arpeggio's support for \nsemantic\nanalysis\n using visitor patter.\n\n\nVisitor is an object with methods named \nvisit_<rule>\n which gets called for \neach node of parse tree produced with the given rule. The processing of the \ntree nodes is done bottom-up.\n\n\nclass CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        \"\"\"\n        Converts node value to float.\n        \"\"\"\n        return float(node.value)\n\n    ...\n\n\n\n\n\nVisit method for the \nnumber\n rule will do the conversion of the matched text\nto \nfloat\n type. This nodes will always be the terminal nodes and will be\nevaluated first.\n\n\n\n    def visit_factor(self, node, children):\n        \"\"\"\n        Applies a sign to the expression or number.\n        \"\"\"\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]\n\n\n\n\n\nFactor will have an optional sign as the first child and whatever matches first\nfrom the ordered choice of number and expression.\nWe take the last element. It must be the result of \nnumber\n or \nexpression\n\nevaluation and apply an optional sing on it.\n\n\n\n\nNote\n\n\nNote that the constant string matches will be removed by the Arpeggio, thus\nyou will never get a constant string match in the children list.\n\n\n\n\n\n    def visit_term(self, node, children):\n        \"\"\"\n        Divides or multiplies factors.\n        Factor nodes will be already evaluated.\n        \"\"\"\n        term = children[0]\n        for i in range(2, len(children), 2):\n            if children[i-1] == \"*\":\n                term *= children[i]\n            else:\n                term /= children[i]\n        return term\n\n\n\n\nterm\n consist of multiplication or divisions. Both operations are left\nassociative so we shall run from left to right. Each even element will be\nevaluated \nfactor\n while each odd element will be an operation to perform.\nAt the end we return the evaluated \nterm\n.\n\n\n    def visit_expression(self, node, children):\n        \"\"\"\n        Adds or substracts terms.\n        Term nodes will be already evaluated.\n        \"\"\"\n        expr = 0\n        start = 0\n        # Check for unary + or - operator\n        if text(children[0]) in \"+-\":\n            start = 1\n\n        for i in range(start, len(children), 2):\n            if i and children[i - 1] == \"-\":\n                expr -= children[i]\n            else:\n                expr += children[i]\n\n        return expr\n\n\n\n\nAnd finally the whole expression consists of additions and subtractions of\nterms. A minor glitch here is a support for unary minus and plus sign.\n\n\nLet's apply this visitor to our parse tree.\n\n\nresult = visit_parse_tree(parse_tree, CalcVisitor(debug=debug))\n\n\n\n\nThe result will be a \nfloat\n which represent the value of the given expression.\n\n\nThe grammar in PEG\n\n\nAs a final note, the same grammar can be specified in \ntextual PEG\nsyntax\n.\n\n\nEither a clean PEG variant:\n\n\nnumber = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")?\n          (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF\n\n\n\n\n\nor traditional PEG variant:\n\n\nnumber <- r'\\d*\\.\\d*|\\d+';\nfactor <- (\"+\" / \"-\")?\n          (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;\n\n\n\n\nThe grammar for textual PEG is parsed using Arpeggio itself and this shows the\nflexibility of the Arpeggio parser.\n\n\nThe code for both parser can be found in the \nCalc\nexample\n.",
            "title": "Calc"
        },
        {
            "location": "/tutorials/calc/#calculator-tutorial",
            "text": "A tutorial for parsing and evaluation of arithmetic expressions.   In this tutorial we will make a parser and evaluator for simple arithmetic\nexpression (numbers and operations - addition, subtraction, multiplication and\ndivision).  The parser will be able to recognize and evaluate following\nexpressions:  2+7-3.6\n3/(3-1)+45*2.17+8\n4*12+5-4*(2-8)\n...  Evaluation will be done using  support for semantic analysis .  Parsing infix expression has additional constraints related to operator\nprecedence. Arpeggio is recursive-descent parser, parsing the input from left to\nright and doing a leftmost derivation. \nThere is a simple technique that will enable proper evaluation in the context\nof a different operator precedence.  Let's start with grammar definition.",
            "title": "Calculator tutorial"
        },
        {
            "location": "/tutorials/calc/#the-grammar",
            "text": "Each  calc  file consists of one or more expressions.   def calc():       return OneOrMore(expression), EOF   Each expression is a sum or subtraction of terms.   def expression(): return term, ZeroOrMore([\"+\", \"-\"], term)   Each term is a multiplication or division of factors.   def term():       return factor, ZeroOrMore([\"*\",\"/\"], factor)   Note  Notice that the order of precendence is from lower to upper.\nThe deeper is the grammar rule, the tighter is the bonding.    Each factor is either a number or an expression inside brackets. The prefix\n  sign is optional. This is a support for unary minus.   def factor():     return Optional([\"+\",\"-\"]), [number, (\"(\", expression, \")\")]   Note  Notice indirect recursion here to  expression . It is not left since the\nopening bracket must be found.    And finally we define  number  using regular expression as   def number():     return _(r'\\d*\\.\\d*|\\d+')",
            "title": "The grammar"
        },
        {
            "location": "/tutorials/calc/#the-parser",
            "text": "Using above grammar specified in  Python\nnotation  we instantiate the parser\nusing  ParserPython  class.    parser = ParserPython(calc)  This parser is able to parse arithmetic expression like this  -(4-1)*5+(2+4.67)+5.89/(.2+7)  and produce parse tree like this    Note  All tree images in this documentation are produced by running the parser\nin  debug mode  and using  visualization\nsupport .   The parsing is done like this:  input_expr = \"-(4-1)*5+(2+4.67)+5.89/(.2+7)\"\nparse_tree = parser.parse(input_expr)  By ordering operation in the grammar form lower to upper precendence we have\ngot the parse tree where the priority is retained. This will help us to easier\nmake an expression evaluation.",
            "title": "The parser"
        },
        {
            "location": "/tutorials/calc/#evaluating-parse-tree",
            "text": "To implement evaluation we shall use Arpeggio's support for  semantic\nanalysis  using visitor patter.  Visitor is an object with methods named  visit_<rule>  which gets called for \neach node of parse tree produced with the given rule. The processing of the \ntree nodes is done bottom-up.  class CalcVisitor(PTNodeVisitor):\n\n    def visit_number(self, node, children):\n        \"\"\"\n        Converts node value to float.\n        \"\"\"\n        return float(node.value)\n\n    ...  Visit method for the  number  rule will do the conversion of the matched text\nto  float  type. This nodes will always be the terminal nodes and will be\nevaluated first.  \n    def visit_factor(self, node, children):\n        \"\"\"\n        Applies a sign to the expression or number.\n        \"\"\"\n        if len(children) == 1:\n            return children[0]\n        sign = -1 if children[0] == '-' else 1\n        return sign * children[-1]  Factor will have an optional sign as the first child and whatever matches first\nfrom the ordered choice of number and expression.\nWe take the last element. It must be the result of  number  or  expression \nevaluation and apply an optional sing on it.   Note  Note that the constant string matches will be removed by the Arpeggio, thus\nyou will never get a constant string match in the children list.   \n    def visit_term(self, node, children):\n        \"\"\"\n        Divides or multiplies factors.\n        Factor nodes will be already evaluated.\n        \"\"\"\n        term = children[0]\n        for i in range(2, len(children), 2):\n            if children[i-1] == \"*\":\n                term *= children[i]\n            else:\n                term /= children[i]\n        return term  term  consist of multiplication or divisions. Both operations are left\nassociative so we shall run from left to right. Each even element will be\nevaluated  factor  while each odd element will be an operation to perform.\nAt the end we return the evaluated  term .      def visit_expression(self, node, children):\n        \"\"\"\n        Adds or substracts terms.\n        Term nodes will be already evaluated.\n        \"\"\"\n        expr = 0\n        start = 0\n        # Check for unary + or - operator\n        if text(children[0]) in \"+-\":\n            start = 1\n\n        for i in range(start, len(children), 2):\n            if i and children[i - 1] == \"-\":\n                expr -= children[i]\n            else:\n                expr += children[i]\n\n        return expr  And finally the whole expression consists of additions and subtractions of\nterms. A minor glitch here is a support for unary minus and plus sign.  Let's apply this visitor to our parse tree.  result = visit_parse_tree(parse_tree, CalcVisitor(debug=debug))  The result will be a  float  which represent the value of the given expression.",
            "title": "Evaluating parse tree"
        },
        {
            "location": "/tutorials/calc/#the-grammar-in-peg",
            "text": "As a final note, the same grammar can be specified in  textual PEG\nsyntax .  Either a clean PEG variant:  number = r'\\d*\\.\\d*|\\d+'\nfactor = (\"+\" / \"-\")?\n          (number / \"(\" expression \")\")\nterm = factor (( \"*\" / \"/\") factor)*\nexpression = term ((\"+\" / \"-\") term)*\ncalc = expression+ EOF  or traditional PEG variant:  number <- r'\\d*\\.\\d*|\\d+';\nfactor <- (\"+\" / \"-\")?\n          (number / \"(\" expression \")\");\nterm <- factor (( \"*\" / \"/\") factor)*;\nexpression <- term ((\"+\" / \"-\") term)*;\ncalc <- expression+ EOF;  The grammar for textual PEG is parsed using Arpeggio itself and this shows the\nflexibility of the Arpeggio parser.  The code for both parser can be found in the  Calc\nexample .",
            "title": "The grammar in PEG"
        },
        {
            "location": "/about/discuss/",
            "text": "Discuss, ask questions\n\n\nIf you want to get help or involve in the community.\n\n\n\n\nFor bug reports, general discussion and help please use \nGitHub issue\ntracker\n.",
            "title": "Discuss"
        },
        {
            "location": "/about/discuss/#discuss-ask-questions",
            "text": "If you want to get help or involve in the community.   For bug reports, general discussion and help please use  GitHub issue\ntracker .",
            "title": "Discuss, ask questions"
        },
        {
            "location": "/about/contributing/",
            "text": "Contributions\n\n\nIf you want to contribute to the Arpeggio project.\n\n\n\n\nArpeggio is open for contributions. You can contribute code, documentation,\ntests, bug reports.  If you plan to make a contribution it would be great if you\nfirst announce that on the discussion forum.\n\n\nFor bug reports please use github \nissue tracker\n.\n\n\nFor code/doc/test contributions do the following:\n\n\n\n\nFork the \nproject on github\n.\n\n\n\n\nClone your fork.\n\n\nTo clone source repository with git and install for development do:\n\n\n$ git clone git@github.com:your_user_name/Arpeggio.git\n$ cd Arpeggio\n$ python setup.py develop\n\n\n\n\n\n\n\nMake a branch for the new feature and switch to it.\n\n\n\n\nMake one or more commits.\n\n\nPush your branch to github.\n\n\nMake a pull request. I will look at the changes and if everything is ok I will pull it in.\n\n\n\n\n\n\nNote\n\n\nFor code contributions please try to adhere to the \nPEP-8 guidelines\n.\nAlthough I am not strict in that regard it is useful to have a common ground for\ncoding style. To make things easier use tools for code checking (PyLint,\nPyFlakes, pep8 etc.).",
            "title": "Contributing"
        },
        {
            "location": "/about/contributing/#contributions",
            "text": "If you want to contribute to the Arpeggio project.   Arpeggio is open for contributions. You can contribute code, documentation,\ntests, bug reports.  If you plan to make a contribution it would be great if you\nfirst announce that on the discussion forum.  For bug reports please use github  issue tracker .  For code/doc/test contributions do the following:   Fork the  project on github .   Clone your fork.  To clone source repository with git and install for development do:  $ git clone git@github.com:your_user_name/Arpeggio.git\n$ cd Arpeggio\n$ python setup.py develop    Make a branch for the new feature and switch to it.   Make one or more commits.  Push your branch to github.  Make a pull request. I will look at the changes and if everything is ok I will pull it in.    Note  For code contributions please try to adhere to the  PEP-8 guidelines .\nAlthough I am not strict in that regard it is useful to have a common ground for\ncoding style. To make things easier use tools for code checking (PyLint,\nPyFlakes, pep8 etc.).",
            "title": "Contributions"
        },
        {
            "location": "/about/license/",
            "text": "Arpeggio is released under the terms of the MIT License\n\n\nCopyright (c) 2009-2015 Igor R. Dejanovi\u0107 \n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.",
            "title": "License"
        }
    ]
}